{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZLjt1FWpn9G"
      },
      "outputs": [],
      "source": [
        "# load packages\n",
        "!pip install mapie\n",
        "!pip install shap\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score, mean_absolute_percentage_error as mape, mean_squared_error as mse\n",
        "from pyarrow import feather as pq\n",
        "import geopandas as gpd\n",
        "import folium\n",
        "from folium import Marker\n",
        "from shapely import geometry\n",
        "from tqdm import tqdm\n",
        "pd.set_option('display.max_columns', None)\n",
        "from ipywidgets import interact\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV\n",
        "import mapie\n",
        "from mapie import regression\n",
        "from mapie.metrics import regression_coverage_score, regression_mean_width_score\n",
        "from mapie.regression import MapieRegressor\n",
        "from mapie.quantile_regression import MapieQuantileRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import shap\n",
        "# Feature Importance\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "# scaler for Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_sMsQoDp3QK"
      },
      "outputs": [],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "# load data for monthly performance\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/Aurora_Thesis/data_converted.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4iaLRHgpn9M"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "data.time = pd.to_datetime(data.time)\n",
        "data = data.reset_index()\n",
        "# need to manually add 2 station Id\n",
        "data.loc[data.station== \"Bologna (BO)\", \"station_id\"] = \"ID1999\"\n",
        "data.loc[data.station== \"San Pietro Capofiume (SPC)\", \"station_id\"] = \"ID1998\"\n",
        "# switch London data\n",
        "data[\"OAtot_2\"] = data.HOA_PMF + data.BBOA_PMF + data.OOAtot_PMF\n",
        "data.loc[data.station == \"London\",\"OAtot_PMF\"] = data.loc[data.station == \"London\",\"OAtot_2\"]\n",
        "# Remove Zurich 2017\n",
        "data = data.loc[(data.station != \"Zurich\") | (data.year != 2017),:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY9ka6Oepn9M"
      },
      "outputs": [],
      "source": [
        "# CLEAN DATA\n",
        "# remove OA with less than 0.1\n",
        "data= data.loc[data.OAtot_PMF >= 0.1, :]\n",
        "# and stations with less than 30 obs.\n",
        "select = (data.groupby(\"station_id\")[\"OAtot_PMF\"].size() > 30).reset_index()\n",
        "data = data.set_index(\"station_id\")\n",
        "data = data.join(select.set_index(\"station_id\"), rsuffix = \"keep\")\n",
        "data = data.loc[ data.OAtot_PMFkeep == True, :]\n",
        "data = data.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OisPMUw2pn9N"
      },
      "outputs": [],
      "source": [
        "# add day of week\n",
        "data[\"day_week\"] = data.time.dt.day_of_week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xreA8KXpn9O"
      },
      "outputs": [],
      "source": [
        "# feature engineering\n",
        "data[\"rc_1_1000-rc_1_100\"] = data[\"road_class_1_1000\"] - data[\"road_class_1_100\"]\n",
        "data[\"rc_2_1000-rc_2_100\"] = data[\"road_class_2_1000\"] - data[\"road_class_2_100\"]\n",
        "data[\"rc_3_1000-rc_3_100\"] = data[\"road_class_3_1000\"] - data[\"road_class_3_100\"]\n",
        "# CAMX proportions of components of OA\n",
        "data[\"p_HOA\"] = data[\"HOA_CAMX\"] / data[\"OAtot_CAMX\"]\n",
        "data[\"p_BBOA\"] = data[\"BBOA_CAMX\"] / data[\"OAtot_CAMX\"]\n",
        "data[\"p_OOAtot\"] = data[\"OOAtot_CAMX\"] / data[\"OAtot_CAMX\"]\n",
        "\n",
        "# need to decorralate some land-use variables\n",
        "data[\"diff_agriculture\"] = data[\"agriculture1000\"] - data[\"agriculture500\"]\n",
        "data[\"diff_airports\"] = data[\"airports1000\"] - data[\"airports500\"]\n",
        "data[\"diff_barren\"] = data[\"barren1000\"] - data[\"barren500\"]\n",
        "data[\"diff_industrial\"] = data[\"industrial1000\"] - data[\"industrial500\"]\n",
        "data[\"diff_industrial_transport\"]= data[\"industrial_transport1000\"] - data[\"industrial_transport500\"]\n",
        "data[\"diff_natural_green\"] =  data[\"natural_green1000\"] - data[\"natural_green500\"]\n",
        "data[\"diff_ports\"] = data[\"ports1000\"] - data[\"ports500\"]\n",
        "data[\"diff_roads_rails\"] = data[\"roads_rails1000\"] - data[\"roads_rails500\"]\n",
        "data[\"diff_snow_ice\"] = data[\"snow_ice1000\"] - data[\"snow_ice500\"]\n",
        "data[\"diff_transport\"] = data[\"transport1000\"] - data[\"transport500\"]\n",
        "data[\"diff_urban_fabric\"] = data[\"urban_fabric1000\"] - data[\"urban_fabric500\"]\n",
        "data[\"diff_urban_green\"] = data[\"urban_green1000\"] - data[\"urban_green500\"]\n",
        "data[\"diff_water\"] = data[\"water1000\"] - data[\"water500\"]\n",
        "data[\"diff_wetlands\"] = data[\"wetlands1000\"] - data[\"wetlands500\"]\n",
        "# also for Population and IMD\n",
        "data[\"diff_population\"] = data[\"population_1000\"] - data[\"population_500\"]\n",
        "data[\"diff_imd\"] = data[\"imd1000\"] - data[\"imd500\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJHG6bkCpn9Z"
      },
      "outputs": [],
      "source": [
        "def my_mape(Y_true, Y_pred):\n",
        "    loss = (np.abs( (Y_true - Y_pred)/(Y_true + 1))).mean()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conformal Prediction at unseen locations"
      ],
      "metadata": {
        "id": "BVicGTDo-WIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CP for unseen locations\n",
        "# Predict at unseen stations\n",
        "np.random.seed(1)\n",
        "n_sp = data.station_id.nunique() # try n_sp equal the number of unique stations\n",
        "# for RF try n_split = number of stations\n",
        "cv = GroupKFold(n_splits = n_sp)\n",
        "res_rf = {}\n",
        "res_boost = {}\n",
        "res_ridge = {}\n",
        "y_pis = {}\n",
        "y_pis_pred = {}\n",
        "y_pis_cqr = {}\n",
        "y_cqr_pred = {}\n",
        "y_qr_lo = {}\n",
        "y_qr_up= {}\n",
        "covars = [\"HOA_CAMX\", \"BBOA_CAMX\", \"OOAtot_CAMX\", \"year\", \"month\",\"day_week\",\n",
        "\"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\",\n",
        "    \"agriculture500\",\"airports500\", \"barren500\", \"industrial500\", \"industrial_transport500\", \"natural_green500\", \"ports500\", \"roads_rails500\", \"snow_ice500\",\n",
        "    \"transport500\", \"urban_fabric500\",\"urban_green500\", \"water500\", \"wetlands500\",\"imd500\", \"population_500\",\"elevation\",\"Lat\",\"Lon\", \"area_grid\",\n",
        "    \"distance_border\", \"distance_mt\"]\n",
        "    # \"diff_agriculture\", \"diff_airports\", \"diff_barren\", \"diff_industrial\", \"diff_industrial_transport\",\n",
        "    # \"diff_natural_green\", \"diff_ports\", \"diff_roads_rails\", \"diff_snow_ice\", \"diff_transport\", \"diff_urban_fabric\", \"diff_urban_green\", \"diff_water\", \"diff_wetlands\",\"diff_population\", \"diff_imd\"\n",
        "X = data.loc[:, covars]\n",
        "X = X.fillna(0)\n",
        "Y = data.loc[:,\"OAtot_PMF\"]\n",
        "station_id = data.loc[:, \"station_id\"]\n",
        "alpha = 0.1\n",
        "# Grouped Cross-Validation\n",
        "for idx, (train_idx, test_idx) in tqdm(enumerate(cv.split(X, Y, station_id))):\n",
        "    # get train ad test folds\n",
        "    X_train = X.iloc[train_idx, :]\n",
        "    Y_train = Y.iloc[train_idx]\n",
        "    X_test = X.iloc[test_idx, :]\n",
        "    Y_test = Y.iloc[test_idx]\n",
        "    # split training in proper train and calibration set (divide stations using groupshuffle function)\n",
        "    train_inds, test_inds =next(GroupShuffleSplit(random_state = 12).split(X_train, Y_train, data.station_id.iloc[train_idx]))\n",
        "    X_train, X_cal, Y_train, Y_cal = X_train.iloc[train_inds,:], X_train.iloc[test_inds,:], Y_train.iloc[train_inds], Y_train.iloc[test_inds]\n",
        "\n",
        "    # Split CQR\n",
        "    bb = GradientBoostingRegressor(loss = \"quantile\", alpha = 0.5, random_state=1)\n",
        "    bb.fit(X_train, Y_train)\n",
        "    alpha = 0.1\n",
        "    mapie = MapieRegressor(bb, cv = \"prefit\", method = \"base\")\n",
        "    mapie.fit(X_cal, Y_cal)\n",
        "\n",
        "    # QUANTILE REGRESSION\n",
        "    lo_boost = GradientBoostingRegressor(loss = \"quantile\", alpha = alpha/2, random_state=1)\n",
        "    up_boost = GradientBoostingRegressor(loss = \"quantile\", alpha = 1-alpha/2, random_state=1)\n",
        "    lo_boost.fit(X_train, Y_train)\n",
        "    up_boost.fit(X_train, Y_train)\n",
        "\n",
        "    # CQR\n",
        "    median_boost = GradientBoostingRegressor(loss = \"quantile\", alpha = 0.5, random_state=1)\n",
        "    mapie_cqr = MapieQuantileRegressor(median_boost, cv = \"split\", method = \"quantile\", alpha = alpha)\n",
        "    mapie_cqr.fit(X_train, Y_train,\n",
        "                    X_calib = X_cal, y_calib = Y_cal)\n",
        "\n",
        "\n",
        "    # Predict at unseen station\n",
        "    test_stations = station_id.iloc[test_idx].unique()\n",
        "    for test_id in test_stations:\n",
        "        res_rf[test_id] = bb.predict(X.loc[data.station_id == test_id,:])\n",
        "        y_pis_pred[test_id], y_pis[test_id] =  mapie.predict(X.loc[data.station_id == test_id,:], alpha = alpha)\n",
        "        y_cqr_pred[test_id], y_pis_cqr[test_id] =  mapie_cqr.predict(X.loc[data.station_id == test_id,:], alpha = alpha)\n",
        "        y_qr_lo[test_id] = lo_boost.predict(X_test)\n",
        "        y_qr_up[test_id] = up_boost.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPqyOF37Rnra",
        "outputId": "5696b722-a9a8-48b5-e925-768f3130a09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "102it [2:29:02, 87.67s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_comparison(station_name):\n",
        "    #sns.set_style(\"whitegrid\")\n",
        "    station_id = data.loc[data.station == station_name, \"station_id\"].iloc[0]\n",
        "    y_obs = data.loc[data.station_id == station_id, \"OAtot_PMF\"].reset_index(drop=True)\n",
        "    y_camx = (data.loc[data.station_id == station_id,[\"HOA_CAMX\",\"BBOA_CAMX\",\"OOAtot_CAMX\"]].apply(np.sum, axis = 1)).reset_index(drop=True)\n",
        "    fig, ax = plt.subplots(1,2, figsize = (20,9), sharey = True)\n",
        "    props = dict(boxstyle='round', facecolor='white', alpha=0.5, edgecolor = \"black\")\n",
        "    y_loc = np.max( (y_obs.max(), y_camx.max()) ) * 0.9\n",
        "    # NAIVE\n",
        "    ax[0].plot(res_rf[station_id], label = \"Prediction\", color = \"green\")\n",
        "    ax[0].plot(y_obs, label =\"Observed OA\", color = \"blue\")\n",
        "    ax[0].plot(y_camx, label =\"CAMx\", color = \"orange\")\n",
        "    ax[0].fill_between(y_obs.index, y_pis[station_id][:,0,0], y_pis[station_id][:,1,0], color = \"green\", alpha = 0.2, label = \"Prediction Interval\")\n",
        "    ax[0].set_title(\"Standard CP\", fontsize = 20)\n",
        "    ax[0].set_ylabel(\"OA\", fontsize = 20)\n",
        "    ax[0].set_yticklabels(ax[0].get_yticks(),fontsize = 16)\n",
        "    #ax[0].set_xticklabels(ax[0].get_xticks(),fontsize = 16)\n",
        "    ax[0].set_xlabel(\"Time\",fontsize = 16)\n",
        "    naive_coverage = np.round(regression_coverage_score(y_obs, y_pis[station_id][:,0,0], y_pis[station_id][:,1,0]),2)\n",
        "    naive_width = (y_pis[station_id][:,1,0] - y_pis[station_id][:,0,0]).mean()\n",
        "    textstr = \"\\n\".join((\n",
        "        r\"$Coverage=%.2f$\" % (naive_coverage, ),\n",
        "        r\"$Width=%.2f$\" % (naive_width, )))\n",
        "    ax[0].text(1,y_loc, textstr, bbox = props,fontsize = 20)\n",
        "    # CQR\n",
        "    ax[1].plot(res_rf[station_id], label = \"Prediction\", color = \"green\")\n",
        "    ax[1].plot(y_obs, label =\"Observed OA\", color = \"blue\")\n",
        "    ax[1].plot(y_camx, label =\"CAMx\", color = \"orange\")\n",
        "    ax[1].fill_between(y_obs.index, y_pis_cqr[station_id][:,0,0], y_pis_cqr[station_id][:,1,0], color = \"green\", alpha = 0.2, label = \"Prediction Interval\")\n",
        "    ax[1].set_title(\"CQR\", fontsize = 20)\n",
        "    cqr_coverage = np.round(regression_coverage_score(y_obs, y_pis_cqr[station_id][:,0,0], y_pis_cqr[station_id][:,1,0]),2)\n",
        "    cqr_width = (y_pis_cqr[station_id][:,1,0] - y_pis_cqr[station_id][:,0,0]).mean()\n",
        "    textstr = \"\\n\".join((\n",
        "        r\"$Coverage=%.2f$\" % (cqr_coverage, ),\n",
        "        r\"$Width=%.2f$\" % (cqr_width, )))\n",
        "    ax[1].text(1,y_loc, textstr, bbox = props, fontsize = 20)\n",
        "    ax[1].set_yticklabels(ax[1].get_yticks(),fontsize = 16)\n",
        "    #ax[1].set_xticklabels(ax[1].get_xticks(),fontsize = 16)$\n",
        "    ax[1].set_xlabel(\"Time\",fontsize = 16)\n",
        "    plt.legend(loc='upper center', bbox_to_anchor=(-0.1, -0.15),\n",
        "                    fancybox=True, shadow=True, ncol=5, fontsize = 20)\n",
        "\n",
        "\n",
        "    fig.suptitle(station_id + \": \" + station_name, fontsize = 24)\n",
        "    for ax in ax.flat:\n",
        "        ax.label_outer()"
      ],
      "metadata": {
        "id": "SpAgm4tRTpxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interact(plot_comparison, station_name = data.station.unique())"
      ],
      "metadata": {
        "id": "6dXW9F7aWW_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get results of average coverage, average normalized width and then station spread in coverage using varius metricls like std, quantiles\n",
        "\n",
        "# dict to save results\n",
        "w_naive = {}\n",
        "cov_naive = {}\n",
        "w_cqr = {}\n",
        "cov_cqr = {}\n",
        "w_qr = {}\n",
        "cov_qr = {}\n",
        "for stat in data.station_id.unique():\n",
        "  y_test = data.loc[data.station_id == stat, \"OAtot_PMF\"]\n",
        "  w_naive[stat] = regression_mean_width_score(y_pis[stat][:,0,0], y_pis[stat][:,1,0])/(y_test.max()-y_test.min())\n",
        "  cov_naive[stat] = regression_coverage_score(y_test, y_pis[stat][:,0,0], y_pis[stat][:,1,0] )\n",
        "  w_cqr[stat] = regression_mean_width_score(y_pis_cqr[stat][:,0,0], y_pis_cqr[stat][:,1,0])/(y_test.max()-y_test.min())\n",
        "  cov_cqr[stat] = regression_coverage_score(y_test, y_pis_cqr[stat][:,0,0], y_pis_cqr[stat][:,1,0] )\n",
        "  w_qr[stat] = regression_mean_width_score(y_qr_lo[stat], y_qr_up[stat])/(y_test.max()-y_test.min())\n",
        "  cov_qr[stat] = regression_coverage_score(y_test, y_qr_lo[stat], y_qr_up[stat] )"
      ],
      "metadata": {
        "id": "nnEFIT9RZdGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unweighted mean\n",
        "print(\"avg. width naive: \", np.mean(list(w_naive.values())))\n",
        "print(\"avg. cov naive: \", np.mean(list(cov_naive.values())))\n",
        "print(\"avg. width cqr: \", np.mean(list(w_cqr.values())))\n",
        "print(\"avg. cov cqr: \", np.mean(list(cov_cqr.values())))\n",
        "print(\"avg. width qr: \", np.mean(list(w_qr.values())))\n",
        "print(\"avg. cov qr: \", np.mean(list(cov_qr.values())))"
      ],
      "metadata": {
        "id": "HrILjRgchrSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unweighted median\n",
        "print(\"avg. width naive: \", np.median(list(w_naive.values())))\n",
        "print(\"avg. cov naive: \", np.median(list(cov_naive.values())))\n",
        "print(\"avg. width cqr: \", np.median(list(w_cqr.values())))\n",
        "print(\"avg. cov cqr: \", np.median(list(cov_cqr.values())))\n",
        "print(\"avg. width qr: \", np.median(list(w_qr.values())))\n",
        "print(\"avg. cov qr: \", np.median(list(cov_qr.values())))"
      ],
      "metadata": {
        "id": "pKx6GpRPT-uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weighted mean with loop (RUN THIS!)\n",
        "w_naivef = 0\n",
        "cov_naivef = 0\n",
        "w_cqrf = 0\n",
        "cov_cqrf = 0\n",
        "w_qrf = 0\n",
        "cov_qrf = 0\n",
        "for stat in data.station_id.unique():\n",
        "  n = len(data.loc[data.station_id == stat, \"OAtot_PMF\"])\n",
        "  w_naivef += w_naive[stat]*n\n",
        "  cov_naivef += cov_naive[stat]*n\n",
        "  w_cqrf += w_cqr[stat]*n\n",
        "  cov_cqrf += cov_cqr[stat]*n\n",
        "  w_qrf += w_qr[stat]*n\n",
        "  cov_qrf += cov_qr[stat]*n"
      ],
      "metadata": {
        "id": "2HobZ3HxinFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weighted mean\n",
        "N = len(data.OAtot_PMF)\n",
        "print(\"avg. width naive: \", w_naivef/N)\n",
        "print(\"avg. cov naive: \", cov_naivef/N)\n",
        "print(\"avg. width cqr: \", w_cqrf/N)\n",
        "print(\"avg. cov cqr: \", cov_cqrf/N)\n",
        "print(\"avg. width qr: \", w_qrf/N)\n",
        "print(\"avg. cov qr: \", cov_qrf/N)"
      ],
      "metadata": {
        "id": "SaPiClu_VLUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unweighted stadard deviation\n",
        "print(\"std. cov naive: \", np.std(list(cov_naive.values())))\n",
        "print(\"std. cov cqr: \", np.std(list(cov_cqr.values())))\n",
        "print(\"std. cov qr: \", np.std(list(cov_qr.values())))\n",
        "# unweighted stadard deviation\n",
        "print(\"std. w naive: \", np.std(list(w_naive.values())))\n",
        "print(\"std. w cqr: \", np.std(list(w_cqr.values())))\n",
        "print(\"std. w qr: \", np.std(list(w_qr.values())))"
      ],
      "metadata": {
        "id": "Got13KIjikW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.offsetbox import AnnotationBbox, TextArea\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import KFold, RandomizedSearchCV, train_test_split\n",
        "from mapie.metrics import (regression_coverage_score,\n",
        "                           regression_mean_width_score)\n",
        "from mapie.subsample import Subsample\n",
        "random_state = 23\n",
        "rng = np.random.default_rng(random_state)\n",
        "round_to = 3\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "aojPLqpjWf5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot all methods x vs y randomly getting stations\n",
        "def sort_y_values(y_test, y_pred, y_pis):\n",
        "    \"\"\"\n",
        "    Sorting the dataset in order to make plots using the fill_between function.\n",
        "    \"\"\"\n",
        "    indices = np.argsort(y_test)\n",
        "    y_test_sorted = np.array(y_test)[indices]\n",
        "    y_pred_sorted = y_pred[indices]\n",
        "    y_lower_bound = y_pis[:, 0, 0][indices]\n",
        "    y_upper_bound = y_pis[:, 1, 0][indices]\n",
        "    return y_test_sorted, y_pred_sorted, y_lower_bound, y_upper_bound\n",
        "\n",
        "def sort_y_values2(y_test, y_pred, y_lower, y_upper):\n",
        "    \"\"\"\n",
        "    Sorting the dataset in order to make plots using the fill_between function.\n",
        "    \"\"\"\n",
        "    indices = np.argsort(y_test)\n",
        "    y_test_sorted = np.array(y_test)[indices]\n",
        "    y_pred_sorted = y_pred[indices]\n",
        "    y_lower_bound = y_lower[indices]\n",
        "    y_upper_bound = y_upper[indices]\n",
        "    return y_test_sorted, y_pred_sorted, y_lower_bound, y_upper_bound\n",
        "\n",
        "\n",
        "def plot_prediction_intervals(\n",
        "    title,\n",
        "    axs,\n",
        "    y_test_sorted,\n",
        "    y_pred_sorted,\n",
        "    lower_bound,\n",
        "    upper_bound,\n",
        "    coverage,\n",
        "    width,\n",
        "    num_plots_idx\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot of the prediction intervals for each different conformal\n",
        "    method.\n",
        "    \"\"\"\n",
        "\n",
        "    axs.yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
        "    axs.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
        "\n",
        "    lower_bound_ = np.take(lower_bound, num_plots_idx)\n",
        "    y_pred_sorted_ = np.take(y_pred_sorted, num_plots_idx)\n",
        "    y_test_sorted_ = np.take(y_test_sorted, num_plots_idx)\n",
        "\n",
        "    error = np.abs(y_pred_sorted_-lower_bound_)\n",
        "\n",
        "    warning1 = y_test_sorted_ > y_pred_sorted_+error\n",
        "    warning2 = y_test_sorted_ < y_pred_sorted_-error\n",
        "    warnings = warning1 + warning2\n",
        "    axs.errorbar(\n",
        "        y_test_sorted_[~warnings],\n",
        "        y_pred_sorted_[~warnings],\n",
        "        yerr=error[~warnings],\n",
        "        capsize=5, marker=\"o\", elinewidth=2, linewidth=0, color = \"blue\",\n",
        "        label=\"Inside prediction interval\"\n",
        "        )\n",
        "    axs.errorbar(\n",
        "        y_test_sorted_[warnings],\n",
        "        y_pred_sorted_[warnings],\n",
        "        yerr=error[warnings],\n",
        "        capsize=5, marker=\"o\", elinewidth=2, linewidth=0, color=\"red\",\n",
        "        label=\"Outside prediction interval\"\n",
        "        )\n",
        "    axs.scatter(\n",
        "        y_test_sorted_[warnings],\n",
        "        y_test_sorted_[warnings],\n",
        "        marker=\"*\", color=\"green\",\n",
        "        label=\"True value\"\n",
        "    )\n",
        "    axs.set_xlabel(\"Observed OA\")\n",
        "    axs.set_ylabel(\"Predicted OA\")\n",
        "    #ab = AnnotationBbox(TextArea(\n",
        "           # f\"Coverage: {np.round(coverage, round_to)}\\n\"\n",
        "          #  + f\"Interval width: {np.round(width, round_to)}\"),xy=(np.min(y_test_sorted_)*3, np.max(y_pred_sorted_+error)*0.95),)\n",
        "\n",
        "    lims = [\n",
        "        np.min([axs.get_xlim(), axs.get_ylim()]),  # min of both axes\n",
        "        np.max([axs.get_xlim(), axs.get_ylim()]),  # max of both axes\n",
        "    ]\n",
        "    pt = (0, 0)\n",
        "    axs.axline(pt, slope=1, color='black', label = \"x=y\")\n",
        "    #axs.plot(0,1, '--', alpha=0.75, color=\"black\", label=\"x=y\")\n",
        "    #axs.add_artist(ab)\n",
        "    axs.set_title(title, fontweight='bold', fontsize = 20)\n",
        "    axs.set_ylabel(axs.get_ylabel(), fontsize = 18)\n",
        "    axs.set_xlabel(axs.get_xlabel(), fontsize = 18)\n",
        "    # change the fontsize\n",
        "    axs.tick_params(axis='x', labelsize=16)\n",
        "    axs.tick_params(axis='y', labelsize=16)\n",
        "    #fig.supxlabel('common_x')\n",
        "    #fig.supylabel('common_y')"
      ],
      "metadata": {
        "id": "JxHcWfMrYbO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_stat(station_name):\n",
        "  stat_id = data.loc[data.station == station_name, \"station_id\"].iloc[0]\n",
        "  y_test = data.loc[data.station_id == stat_id, \"OAtot_PMF\"]\n",
        "  y_test_sorted = {}\n",
        "  y_pred_sorted = {}\n",
        "  y_lower_sorted = {}\n",
        "  y_upper_sorted = {}\n",
        "  y_test_sorted[\"Standard CP\"] , y_pred_sorted[\"Standard CP\"], y_lower_sorted[\"Standard CP\"], y_upper_sorted[\"Standard CP\"] = sort_y_values(y_test, y_cqr_pred[stat_id], y_pis[stat_id])\n",
        "  y_test_sorted[\"CQR\"] , y_pred_sorted[\"CQR\"], y_lower_sorted[\"CQR\"], y_upper_sorted[\"CQR\"]= sort_y_values(y_test, y_cqr_pred[stat_id], y_pis_cqr[stat_id])\n",
        "\n",
        "\n",
        "  fig, ax = plt.subplots(1,2, figsize = (16,9), sharey = True)\n",
        "  sns.set_style(\"whitegrid\")\n",
        "  axs = [ ax[0], ax[1] ]\n",
        "  strategy = [\"Standard CP\", \"CQR\"]\n",
        "  perc_obs_plot = 1\n",
        "  num_plots = rng.choice(len(y_test), int(perc_obs_plot*len(y_test)), replace=False)\n",
        "  for axis, strat in zip(axs, strategy):\n",
        "    plot_prediction_intervals(\n",
        "                    strat,\n",
        "                    axis,\n",
        "                    y_test_sorted[strat],\n",
        "                    y_pred_sorted[strat],\n",
        "                    y_lower_sorted[strat],\n",
        "                    y_upper_sorted[strat],\n",
        "                    10,\n",
        "                    2,\n",
        "                    num_plots\n",
        "                    )\n",
        "\n",
        "  lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
        "  lines, labels = [sum(_, []) for _ in zip(*lines_labels)]\n",
        "  plt.legend(\n",
        "                lines[:4], labels[:4],\n",
        "                loc='upper center',\n",
        "                bbox_to_anchor=(0, -0.225),\n",
        "                fancybox=True,\n",
        "                shadow=True,\n",
        "                ncol=2, fontsize = 20\n",
        "            )\n",
        "  for ax in ax.flat:\n",
        "        ax.label_outer()\n",
        "  plt.suptitle(station_name, fontsize = 30)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "wKOumSFMZxnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interact(plot_stat, station_name = data.station.unique())"
      ],
      "metadata": {
        "id": "H7LBErygaTg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multiple stations plot\n",
        "fig, ax = plt.subplots(1,2, figsize = (20,9), sharey = True)\n",
        "sns.set_style(\"whitegrid\")\n",
        "axs = [ax[0], ax[1]]\n",
        "strategy = [\"Standard CP\", \"CQR\"]\n",
        "perc_obs_plot = 0.01\n",
        "\n",
        "for idx, stat_id in enumerate(data.station_id.unique()):\n",
        "    y_test = data.loc[data.station_id == stat_id, \"OAtot_PMF\"]\n",
        "    num_plots = rng.choice(len(y_test), int(perc_obs_plot*len(y_test)), replace=False)\n",
        "    y_test_sorted = {}\n",
        "    y_pred_sorted = {}\n",
        "    y_lower_sorted = {}\n",
        "    y_upper_sorted = {}\n",
        "    y_test_sorted[\"Standard CP\"] , y_pred_sorted[\"Standard CP\"], y_lower_sorted[\"Standard CP\"], y_upper_sorted[\"Standard CP\"] = sort_y_values(y_test, y_pis_pred[stat_id], y_pis[stat_id])\n",
        "    y_test_sorted[\"CQR\"] , y_pred_sorted[\"CQR\"], y_lower_sorted[\"CQR\"], y_upper_sorted[\"CQR\"]= sort_y_values(y_test, y_cqr_pred[stat_id], y_pis_cqr[stat_id])\n",
        "\n",
        "    for idx, (axis, strat) in enumerate(zip(axs, strategy)):\n",
        "        plot_prediction_intervals(\n",
        "                strat,\n",
        "                axis,\n",
        "                y_test_sorted[strat],\n",
        "                y_pred_sorted[strat],\n",
        "                y_lower_sorted[strat],\n",
        "                y_upper_sorted[strat],\n",
        "                10,\n",
        "                2,\n",
        "                num_plots # num_plots\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "lines_labels = [axis.get_legend_handles_labels() for ax in fig.axes]\n",
        "lines, labels = [sum(_, []) for _ in zip(*lines_labels)]\n",
        "plt.legend(\n",
        "                      lines[:2] + lines[-2:], labels[:2] + labels[-2:],\n",
        "                      loc='upper center',\n",
        "                      bbox_to_anchor=(0, -0.15),\n",
        "                      fancybox=True,\n",
        "                      shadow=True,\n",
        "                      ncol=2, fontsize = 20\n",
        "                  )\n",
        "for ax in ax.flat:\n",
        "        ax.label_outer()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WmwzHyuJYfPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "IML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}