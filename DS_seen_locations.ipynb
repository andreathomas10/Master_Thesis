{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZLjt1FWpn9G"
      },
      "outputs": [],
      "source": [
        "# load packages\n",
        "!pip install mapie\n",
        "!pip install shap\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score, mean_absolute_percentage_error as mape, mean_squared_error as mse\n",
        "from pyarrow import feather as pq\n",
        "import geopandas as gpd\n",
        "import folium\n",
        "from folium import Marker\n",
        "from shapely import geometry\n",
        "from tqdm import tqdm\n",
        "pd.set_option('display.max_columns', None)\n",
        "from ipywidgets import interact\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV\n",
        "import mapie\n",
        "from mapie import regression\n",
        "from mapie.metrics import regression_coverage_score, regression_mean_width_score\n",
        "from mapie.regression import MapieRegressor\n",
        "from mapie.quantile_regression import MapieQuantileRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import shap\n",
        "# Feature Importance\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "# scaler for Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_sMsQoDp3QK"
      },
      "outputs": [],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "# load data for monthly performance\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/Aurora_Thesis/data_converted.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4iaLRHgpn9M"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "data.time = pd.to_datetime(data.time)\n",
        "data = data.reset_index()\n",
        "# need to manually add 2 station Id\n",
        "data.loc[data.station== \"Bologna (BO)\", \"station_id\"] = \"ID1999\"\n",
        "data.loc[data.station== \"San Pietro Capofiume (SPC)\", \"station_id\"] = \"ID1998\"\n",
        "# switch London data\n",
        "data[\"OAtot_2\"] = data.HOA_PMF + data.BBOA_PMF + data.OOAtot_PMF\n",
        "data.loc[data.station == \"London\",\"OAtot_PMF\"] = data.loc[data.station == \"London\",\"OAtot_2\"]\n",
        "# Remove Zurich 2017\n",
        "data = data.loc[(data.station != \"Zurich\") | (data.year != 2017),:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY9ka6Oepn9M"
      },
      "outputs": [],
      "source": [
        "# CLEAN DATA\n",
        "# remove OA with less than 0.1\n",
        "data= data.loc[data.OAtot_PMF >= 0.1, :]\n",
        "# and stations with less than 30 obs.\n",
        "select = (data.groupby(\"station_id\")[\"OAtot_PMF\"].size() > 30).reset_index()\n",
        "data = data.set_index(\"station_id\")\n",
        "data = data.join(select.set_index(\"station_id\"), rsuffix = \"keep\")\n",
        "data = data.loc[ data.OAtot_PMFkeep == True, :]\n",
        "data = data.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OisPMUw2pn9N"
      },
      "outputs": [],
      "source": [
        "# add day of week\n",
        "data[\"day_week\"] = data.time.dt.day_of_week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xreA8KXpn9O"
      },
      "outputs": [],
      "source": [
        "# feature engineering\n",
        "data[\"rc_1_1000-rc_1_100\"] = data[\"road_class_1_1000\"] - data[\"road_class_1_100\"]\n",
        "data[\"rc_2_1000-rc_2_100\"] = data[\"road_class_2_1000\"] - data[\"road_class_2_100\"]\n",
        "data[\"rc_3_1000-rc_3_100\"] = data[\"road_class_3_1000\"] - data[\"road_class_3_100\"]\n",
        "# CAMX proportions of components of OA\n",
        "data[\"p_HOA\"] = data[\"HOA_CAMX\"] / data[\"OAtot_CAMX\"]\n",
        "data[\"p_BBOA\"] = data[\"BBOA_CAMX\"] / data[\"OAtot_CAMX\"]\n",
        "data[\"p_OOAtot\"] = data[\"OOAtot_CAMX\"] / data[\"OAtot_CAMX\"]\n",
        "\n",
        "# need to decorralate some land-use variables\n",
        "data[\"diff_agriculture\"] = data[\"agriculture1000\"] - data[\"agriculture500\"]\n",
        "data[\"diff_airports\"] = data[\"airports1000\"] - data[\"airports500\"]\n",
        "data[\"diff_barren\"] = data[\"barren1000\"] - data[\"barren500\"]\n",
        "data[\"diff_industrial\"] = data[\"industrial1000\"] - data[\"industrial500\"]\n",
        "data[\"diff_industrial_transport\"]= data[\"industrial_transport1000\"] - data[\"industrial_transport500\"]\n",
        "data[\"diff_natural_green\"] =  data[\"natural_green1000\"] - data[\"natural_green500\"]\n",
        "data[\"diff_ports\"] = data[\"ports1000\"] - data[\"ports500\"]\n",
        "data[\"diff_roads_rails\"] = data[\"roads_rails1000\"] - data[\"roads_rails500\"]\n",
        "data[\"diff_snow_ice\"] = data[\"snow_ice1000\"] - data[\"snow_ice500\"]\n",
        "data[\"diff_transport\"] = data[\"transport1000\"] - data[\"transport500\"]\n",
        "data[\"diff_urban_fabric\"] = data[\"urban_fabric1000\"] - data[\"urban_fabric500\"]\n",
        "data[\"diff_urban_green\"] = data[\"urban_green1000\"] - data[\"urban_green500\"]\n",
        "data[\"diff_water\"] = data[\"water1000\"] - data[\"water500\"]\n",
        "data[\"diff_wetlands\"] = data[\"wetlands1000\"] - data[\"wetlands500\"]\n",
        "# also for Population and IMD\n",
        "data[\"diff_population\"] = data[\"population_1000\"] - data[\"population_500\"]\n",
        "data[\"diff_imd\"] = data[\"imd1000\"] - data[\"imd500\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlhoFVyrpn9R"
      },
      "outputs": [],
      "source": [
        "# Get OA\n",
        "data = data.loc[data.OAtot_PMF.isnull()==False,:]\n",
        "data = data.sort_values(by=\"time\")\n",
        "# Get Y\n",
        "Y = data.loc[:, [\"time\",\"station_id\",\"station\",\"OAtot_PMF\"]]\n",
        "Y = Y.set_index(\"time\")\n",
        "# Get X design\n",
        "# probabaly better the 3 components\n",
        "X = data.loc[: , [\"time\", \"station\",\"station_id\", \"HOA_CAMX\", \"BBOA_CAMX\", \"OOAtot_CAMX\", \"year\", \"month\",\"day_week\",\n",
        "\"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\"]]\n",
        "X = X.set_index(\"time\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LIFONklpn9S"
      },
      "outputs": [],
      "source": [
        "# down-scale at station\n",
        "def down_scale(station_name:str):\n",
        "    rf = RandomForestRegressor(random_state=99)\n",
        "    boost = GradientBoostingRegressor(random_state=00)\n",
        "    # get station\n",
        "    X_station = X.loc[X.station == station_name, :]\n",
        "    Y_station = Y.loc[Y.station == station_name, :]\n",
        "    # train and test split (as in training data proportion)\n",
        "    split = 0.75\n",
        "    index_train = int(np.floor(len(X_station) * split))\n",
        "    Y_train_station = Y_station.iloc[:index_train,:]\n",
        "    Y_test_station = Y_station.iloc[index_train:, :]\n",
        "    X_train_station = X_station.iloc[:index_train,:]\n",
        "    X_test_station = X_station.iloc[index_train:,:]\n",
        "\n",
        "\n",
        "    # fit models\n",
        "    covars = [\"HOA_CAMX\", \"BBOA_CAMX\", \"OOAtot_CAMX\", \"year\", \"month\",\"day_week\",\n",
        "    \"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\"]\n",
        "    # grid search for time series\n",
        "    tscv = TimeSeriesSplit(n_splits = 5)\n",
        "    param_rf = {\"max_features\":[\"sqrt\",\"log2\"]}\n",
        "    param_boost = {\"max_depth\":[3,5,10],  \"learning_rate\":[0.001, 0.01,0.1]} # also 0.001 for monthly\n",
        "    # RF\n",
        "    clf = GridSearchCV(rf, param_grid = param_rf, cv = tscv.split(X_train_station.loc[:, covars]))\n",
        "    clf.fit(X_train_station.loc[:, covars], Y_train_station.OAtot_PMF)\n",
        "    # BOOSTING\n",
        "    clf2 = GridSearchCV(boost, param_grid= param_boost, cv = tscv.split(X_train_station.loc[:, covars]))\n",
        "    clf2.fit(X_train_station.loc[:, covars], Y_train_station.OAtot_PMF)\n",
        "    # RIDGE\n",
        "    # standardize features\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train_station.loc[:,covars])\n",
        "    X_train_scaled = pd.DataFrame(scaler.transform(X_train_station.loc[:,covars]))\n",
        "\n",
        "    lm = RidgeCV(cv = tscv)\n",
        "    lm.fit(X_train_scaled, Y_train_station.OAtot_PMF)\n",
        "    #rf.fit(X_train_station.loc[:, covars], Y_train_station.OAtot_PMF)\n",
        "    #boost.fit(X_train_station.loc[:, covars], Y_train_station.OAtot_PMF)\n",
        "\n",
        "    # predict on test set\n",
        "    rf_pred = clf.predict(X_test_station.loc[:, covars])\n",
        "    # features for ridge\n",
        "    X_test_scaled = pd.DataFrame(scaler.transform(X_test_station.loc[:, covars]))\n",
        "    lm_pred = lm.predict(X_test_scaled)\n",
        "    boost_pred = clf2.predict(X_test_station.loc[:, covars])\n",
        "    camx_pred = X_test_station.HOA_CAMX + X_test_station.BBOA_CAMX +  X_test_station.OOAtot_CAMX\n",
        "    # compute error on test set\n",
        "    mse_full_rf = mse(Y_test_station.OAtot_PMF, rf_pred)\n",
        "    mse_full_boost = mse(Y_test_station.OAtot_PMF, boost_pred)\n",
        "    mse_full_lm = mse(Y_test_station.OAtot_PMF, lm_pred)\n",
        "    mse_full_camx = mse(Y_test_station.OAtot_PMF, camx_pred)\n",
        "    # plot resulting predictions\n",
        "    plt.figure(figsize=(16,9))\n",
        "    plt.plot(Y_test_station.OAtot_PMF, label = \"Truth\")\n",
        "    plt.plot(Y_test_station.reset_index().time, rf_pred, label = \"rf\")\n",
        "    #plt.plot(Y_test_station.reset_index().time, boost_pred,label = \"boost\")\n",
        "    #plt.plot(Y_test_station.reset_index().time, lm_pred, label =\"linear\")\n",
        "    plt.plot(Y_test_station.reset_index().time, camx_pred,label = \"CAMx\")\n",
        "    plt.title(station_name)\n",
        "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
        "            fancybox=True, shadow=True, ncol=5)\n",
        "\n",
        "    # print mse\n",
        "    print(\"mse rf\", mse_full_rf)\n",
        "    print(\"mse boost\", mse_full_boost)\n",
        "    print(\"mse lm\", mse_full_lm)\n",
        "    print(\"mse CAMx\", mse_full_camx)\n",
        "\n",
        "    #same but without CAMx's input\n",
        "    # fit models\n",
        "    covars = [\"year\", \"month\",\"day_week\",\n",
        "    \"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\"]\n",
        "    # fit models\n",
        "    # RF\n",
        "    clf = GridSearchCV(rf, param_grid= param_rf, cv =tscv.split(X_train_station.loc[:, covars]) )\n",
        "    clf.fit(X_train_station.loc[:, covars], Y_train_station.OAtot_PMF)\n",
        "    # BOOSTING\n",
        "    clf2 = GridSearchCV(boost, param_grid= param_boost, cv = tscv.split(X_train_station.loc[:, covars]))\n",
        "    clf2.fit(X_train_station.loc[:, covars], Y_train_station.OAtot_PMF)\n",
        "    # RIDGE\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train_station.loc[:, covars])\n",
        "    X_train_scaled = pd.DataFrame(X_train_station.loc[:, covars])\n",
        "    lm.fit( X_train_scaled, Y_train_station.OAtot_PMF)\n",
        "    #rf.fit(X_train_station.loc[:, covars], Y_train_station.OAtot_PMF)\n",
        "    #boost.fit(X_train_station.loc[:, covars], Y_train_station.OAtot_PMF)\n",
        "\n",
        "    # predict on test set\n",
        "    rf_pred = clf.predict(X_test_station.loc[:, covars])\n",
        "    X_test_scaled = pd.DataFrame(X_test_station.loc[:, covars])\n",
        "    lm_pred = lm.predict(X_test_scaled)\n",
        "    boost_pred = clf2.predict(X_test_station.loc[:, covars])\n",
        "    camx_pred = X_test_station.HOA_CAMX + X_test_station.BBOA_CAMX +  X_test_station.OOAtot_CAMX\n",
        "    # compute error on test set\n",
        "    mse_part_rf = mse(Y_test_station.OAtot_PMF, rf_pred)\n",
        "    mse_part_boost = mse(Y_test_station.OAtot_PMF, boost_pred)\n",
        "    mse_part_lm = mse(Y_test_station.OAtot_PMF, lm_pred)\n",
        "    mse_part_camx = mse(Y_test_station.OAtot_PMF, camx_pred)\n",
        "\n",
        "    # print mse\n",
        "    print(\"mse rf\", mse_part_rf)\n",
        "    print(\"mse boost\", mse_part_boost)\n",
        "    print(\"mse lm\", mse_part_lm)\n",
        "    print(\"mse CAMx\", mse_part_camx)\n",
        "\n",
        "    # plot resulting predictions\n",
        "    plt.figure(figsize=(16,9))\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    plt.plot(Y_test_station.reset_index(drop=True).index, Y_test_station.OAtot_PMF, label = \"OA\",color = \"blue\")\n",
        "    plt.plot(Y_test_station.reset_index(drop=True).index, rf_pred, label = \"Predicted OA\", color = \"green\")\n",
        "    #plt.plot(Y_test_station.reset_index().time, boost_pred,label = \"boost\")\n",
        "    plt.plot(Y_test_station.reset_index(drop=True).index, lm_pred, label =\"linear\")\n",
        "    plt.plot(Y_test_station.reset_index(drop=True).index, camx_pred,label = \"CAMx\", color = \"orange\")\n",
        "    plt.title(station_name, fontsize = 24)\n",
        "    plt.ylabel(\"OA\", fontsize = 24)\n",
        "    plt.yticks(fontsize = 20)\n",
        "    plt.xticks(fontsize = 20)\n",
        "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
        "            fancybox=True, shadow=True, ncol=5, fontsize = 20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scSMHxSspn9S"
      },
      "outputs": [],
      "source": [
        "interact(down_scale, station_name = X.station.unique())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# target metric of choice\n",
        "def my_mape(Y_true, Y_pred):\n",
        "    loss = (np.abs( (Y_true - Y_pred)/(Y_true+1))).mean()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "ZmO-d_0zdqB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa-2jY30pn9T"
      },
      "outputs": [],
      "source": [
        "# down-scale at station (function to get results--> NO PLOTS)\n",
        "def down_scale(station_name:str):\n",
        "    rf = RandomForestRegressor(random_state=99, n_estimators = 500)\n",
        "    boost = GradientBoostingRegressor(random_state=00)\n",
        "    lm = RidgeCV()\n",
        "    # get station\n",
        "    X_station = X.loc[X.station_id == station_name, :]\n",
        "    Y_station = Y.loc[Y.station_id == station_name, :]\n",
        "    # train and test split (as in training data proportion)\n",
        "    split = 0.75\n",
        "    index_train = int(np.floor(len(X_station) * split))\n",
        "    Y_train_station = Y_station.iloc[:index_train,:]\n",
        "    Y_test_station = Y_station.iloc[index_train:, :]\n",
        "    X_train_station = X_station.iloc[:index_train,:]\n",
        "    X_test_station = X_station.iloc[index_train:,:]\n",
        "\n",
        "    # fit models\n",
        "    covars = [\"HOA_CAMX\", \"BBOA_CAMX\", \"OOAtot_CAMX\", \"year\", \"month\",\"day_week\",\n",
        "    \"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\"]\n",
        "    # grid search\n",
        "    tscv = TimeSeriesSplit(n_splits = 5)\n",
        "    param_rf = {\"max_features\":[\"sqrt\",\"log2\"]}\n",
        "    param_boost = {\"max_depth\":[3,5,10],  \"learning_rate\":[0.001, 0.01,0.1]}\n",
        "    # RF\n",
        "    clf = GridSearchCV(rf, param_grid= param_rf, cv = tscv)\n",
        "    clf.fit(X_train_station.loc[:, covars], Y_train_station.OAtot_PMF)\n",
        "    # BOOSTING\n",
        "    clf2 = GridSearchCV(boost, param_grid= param_boost, cv = tscv)\n",
        "    clf2.fit(X_train_station.loc[:, covars], Y_train_station.OAtot_PMF)\n",
        "    # RIDGE\n",
        "    # standardize features\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train_station.loc[:,covars])\n",
        "    X_train_scaled = pd.DataFrame(scaler.transform(X_train_station.loc[:,covars]))\n",
        "    lm = RidgeCV(cv = tscv)\n",
        "    lm.fit(X_train_scaled, Y_train_station.OAtot_PMF)\n",
        "\n",
        "    # predict on test set\n",
        "    rf_pred = clf.predict(X_test_station.loc[:, covars])\n",
        "    lm_pred = lm.predict(pd.DataFrame(scaler.transform(X_test_station.loc[:, covars])))\n",
        "    boost_pred = clf2.predict(X_test_station.loc[:, covars])\n",
        "    camx_pred = X_test_station.HOA_CAMX + X_test_station.BBOA_CAMX +  X_test_station.OOAtot_CAMX\n",
        "    # compute error on test set\n",
        "    mse_full_rf = mse(Y_test_station.OAtot_PMF, rf_pred)\n",
        "    mse_full_boost = mse(Y_test_station.OAtot_PMF, boost_pred)\n",
        "    mse_full_lm = mse(Y_test_station.OAtot_PMF, lm_pred)\n",
        "    mse_full_camx = mse(Y_test_station.OAtot_PMF, camx_pred)\n",
        "    mape_full_rf = my_mape(Y_test_station.OAtot_PMF, rf_pred)\n",
        "    mape_full_boost = my_mape(Y_test_station.OAtot_PMF, boost_pred)\n",
        "    mape_full_lm = my_mape(Y_test_station.OAtot_PMF, lm_pred)\n",
        "    mape_full_camx = my_mape(Y_test_station.OAtot_PMF, camx_pred)\n",
        "\n",
        "    #same but without CAMx's input\n",
        "    # fit models\n",
        "    covars = [\"year\", \"month\",\"day_week\",\n",
        "    \"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\"]\n",
        "    # RF\n",
        "    clf = GridSearchCV(rf, param_grid= param_rf)\n",
        "    clf.fit(X_train_station.loc[:, covars], Y_train_station.OAtot_PMF)\n",
        "    # BOOSTING\n",
        "    clf2 = GridSearchCV(boost, param_grid= param_boost)\n",
        "    clf2.fit(X_train_station.loc[:, covars], Y_train_station.OAtot_PMF)\n",
        "    # RIDGE\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train_station.loc[:,covars])\n",
        "    X_train_scaled = pd.DataFrame(scaler.transform(X_train_station.loc[:,covars]))\n",
        "    lm.fit(X_train_scaled, Y_train_station.OAtot_PMF)\n",
        "\n",
        "    # predict on test set\n",
        "    rf_pred = clf.predict(X_test_station.loc[:, covars])\n",
        "    lm_pred = lm.predict(pd.DataFrame(scaler.transform(X_test_station.loc[:, covars])))\n",
        "    boost_pred = clf2.predict(X_test_station.loc[:, covars])\n",
        "    # compute error on test set\n",
        "    mse_part_rf = mse(Y_test_station.OAtot_PMF, rf_pred)\n",
        "    mse_part_boost = mse(Y_test_station.OAtot_PMF, boost_pred)\n",
        "    mse_part_lm = mse(Y_test_station.OAtot_PMF, lm_pred)\n",
        "    mape_part_rf = my_mape(Y_test_station.OAtot_PMF, rf_pred)\n",
        "    mape_part_boost = my_mape(Y_test_station.OAtot_PMF, boost_pred)\n",
        "    mape_part_lm = my_mape(Y_test_station.OAtot_PMF, lm_pred)\n",
        "    n_test = len(Y_test_station)\n",
        "\n",
        "\n",
        "    return mse_full_rf, mape_full_rf, mse_full_boost, mape_full_boost, mse_full_lm, mape_full_lm, mse_full_camx, mape_full_camx, mse_part_rf, mape_part_rf,mse_part_boost,mape_part_boost, mse_part_lm,mape_part_lm, n_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dict to store results\n",
        "full_rf_ind_mse = {}\n",
        "full_boost_ind_mse = {}\n",
        "full_ridge_ind_mse = {}\n",
        "full_rf_ind_mape = {}\n",
        "full_boost_ind_mape = {}\n",
        "full_ridge_ind_mape = {}\n",
        "camx_mse = {}\n",
        "part_rf_ind_mse = {}\n",
        "part_boost_ind_mse = {}\n",
        "part_ridge_ind_mse = {}\n",
        "part_rf_ind_mape = {}\n",
        "part_boost_ind_mape = {}\n",
        "part_ridge_ind_mape = {}\n",
        "camx_mape = {}\n",
        "# loop over every station\n",
        "for stat in tqdm(data.station_id.unique()):\n",
        "  full_rf_ind_mse[stat], full_rf_ind_mape[stat], full_boost_ind_mse[stat], full_boost_ind_mape[stat], full_ridge_ind_mse[stat], full_ridge_ind_mape[stat], camx_mse[stat], camx_mape[stat], part_rf_ind_mse[stat], part_rf_ind_mape[stat],part_boost_ind_mse[stat],part_boost_ind_mape[stat], part_ridge_ind_mse[stat],part_ridge_ind_mape[stat], n_test = down_scale(stat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC30pqyfc3gK",
        "outputId": "746bff18-4f8c-4a3d-c7be-91b6a4c9a4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 102/102 [1:06:19<00:00, 39.01s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save all dictionaries in JSON formar\n",
        "dictionaries = [full_rf_ind_mse, full_rf_ind_mape, full_boost_ind_mse, full_boost_ind_mape, full_ridge_ind_mse, full_ridge_ind_mape, camx_mse, camx_mape,\n",
        "                part_rf_ind_mse, part_rf_ind_mape, part_boost_ind_mse, part_boost_ind_mape, part_ridge_ind_mse, part_ridge_ind_mape]\n",
        "names = [\"full_rf_ind_mse\", \"full_rf_ind_mape\", \"full_boost_ind_mse\", \"full_boost_ind_mape\", \"full_ridge_ind_mse\", \"full_ridge_ind_mape\", \"camx_mse\", \"camx_mape\",\n",
        "                \"part_rf_ind_mse\", \"part_rf_ind_mape\", \"part_boost_ind_mse\", \"part_boost_ind_mape\", \"part_ridge_ind_mse\", \"part_ridge_ind_mape\"]\n",
        "for di, di_name in zip(dictionaries, names):\n",
        "  with open(di_name +\".json\", \"w\") as json_file:\n",
        "    json.dump(di, json_file)"
      ],
      "metadata": {
        "id": "tELUO4Poh-Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get results - unweighted\n",
        "print(\"mse rf full\", np.mean(list(full_rf_ind_mse.values())), \"std.dev.: \", np.std(list(full_rf_ind_mse.values())))\n",
        "print(\"mse boost full\", np.mean(list(full_boost_ind_mse.values())), \"std.dev.: \", np.std(list(full_boost_ind_mse.values())))\n",
        "print(\"mse ridge full\", np.mean(list(full_ridge_ind_mse.values())), \"std.dev.: \", np.std(list(full_ridge_ind_mse.values())))\n",
        "print(\"mse camx\", np.mean(list(camx_mse.values())), \"std.dev.: \", np.std(list(camx_mse.values())))\n",
        "print(\"mse rf part\", np.mean(list(part_rf_ind_mse.values())), \"std.dev.: \", np.std(list(part_rf_ind_mse.values())))\n",
        "print(\"mse boost part\", np.mean(list(part_boost_ind_mse.values())), \"std.dev.: \", np.std(list(part_boost_ind_mse.values())))\n",
        "print(\"mse ridge part\", np.mean(list(part_ridge_ind_mse.values())), \"std.dev.: \", np.std(list(part_ridge_ind_mse.values())))\n",
        "print(\"mape rf full\", np.mean(list(full_rf_ind_mape.values())), \"std.dev.: \", np.std(list(full_rf_ind_mape.values())))\n",
        "print(\"mape boost full\", np.mean(list(full_boost_ind_mape.values())), \"std.dev.: \", np.std(list(full_boost_ind_mape.values())))\n",
        "print(\"mape ridge full\", np.mean(list(full_ridge_ind_mape.values())), \"std.dev.: \", np.std(list(full_ridge_ind_mape.values())))\n",
        "print(\"mape rf part\", np.mean(list(part_rf_ind_mape.values())), \"std.dev.: \", np.std(list(part_rf_ind_mape.values())))\n",
        "print(\"mape boost part\", np.mean(list(part_boost_ind_mape.values())), \"std.dev.: \", np.std(list(part_boost_ind_mape.values())))\n",
        "print(\"mape ridge part\", np.mean(list(part_ridge_ind_mape.values())), \"std.dev.: \", np.std(list(part_ridge_ind_mape.values())))\n",
        "print(\"mape camx\", np.mean(list(camx_mape.values())), \"std.dev.: \", np.std(list(camx_mape.values())))"
      ],
      "metadata": {
        "id": "guebDX57gia0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot for mse\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize = (16,9))\n",
        "labels = [\"CAMx\",\"RF\",\"RF*\",\"Boost\",\"Boost*\",\"Ridge\",\"Ridge*\"]\n",
        "positions = [0,3,4,7,8,11,12]\n",
        "plt.boxplot([list(camx_mse.values()), list(full_rf_ind_mse.values()),list(part_rf_ind_mse.values()), list(full_boost_ind_mse.values()),list(part_boost_ind_mse.values()), list(full_ridge_ind_mse.values()), list(part_ridge_ind_mse.values())], patch_artist = True, positions = positions,labels = labels)\n",
        "plt.yscale(\"log\")\n",
        "plt.ylabel(\"log(MSE)\", fontsize = 20)\n",
        "plt.tick_params(axis='x', labelsize=20)\n",
        "plt.tick_params(axis='y', labelsize=24)\n",
        "plt.title(\"MSE for down-scaling: Individual Models\", fontsize = 30)"
      ],
      "metadata": {
        "id": "22ihzAazrogL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot for mape\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize = (16,9))\n",
        "labels = [\"CAMx\",\"RF\",\"RF*\",\"Boost\",\"Boost*\",\"Ridge\",\"Ridge*\"]\n",
        "positions = [0,3,4,7,8,11,12]\n",
        "plt.boxplot([list(camx_mape.values()), list(full_rf_ind_mape.values()),list(part_rf_ind_mape.values()), list(full_boost_ind_mape.values()),list(part_boost_ind_mape.values()), list(full_ridge_ind_mape.values()), list(part_ridge_ind_mape.values())], patch_artist = True, positions = positions,labels = labels)\n",
        "plt.yscale(\"log\")\n",
        "plt.ylabel(\"log(MAPE)\", fontsize = 20)\n",
        "plt.tick_params(axis='x', labelsize=24)\n",
        "plt.tick_params(axis='y', labelsize=24)\n",
        "plt.title(\"MAPE for down-scaling: Individual Models\", fontsize = 30)"
      ],
      "metadata": {
        "id": "TKbE00AmwQ7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJjWdZTZyzVr"
      },
      "source": [
        "# Global model, ie train on all stations at the same time! and account for station once with dummy and once with random effect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get OA\n",
        "data = data.loc[data.OAtot_PMF.isnull()==False,:]\n",
        "data = data.sort_values(by=\"time\")\n",
        "# Get Y\n",
        "Y = data.loc[:, [\"time\",\"station_id\",\"station\",\"OAtot_PMF\"]]\n",
        "Y = Y.set_index(\"time\")\n",
        "# Get X design\n",
        "# probabaly better the 3 components\n",
        "covars = [\"time\", \"station\", \"station_id\", \"OAtot_PMF\", \"HOA_CAMX\", \"BBOA_CAMX\", \"OOAtot_CAMX\", \"year\", \"month\",\"day_week\",\n",
        "\"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\",\"diff_agriculture\", \"diff_airports\", \"diff_barren\", \"diff_industrial\", \"diff_industrial_transport\",\n",
        "    \"diff_natural_green\", \"diff_ports\", \"diff_roads_rails\", \"diff_snow_ice\", \"diff_transport\", \"diff_urban_fabric\", \"diff_urban_green\", \"diff_water\", \"diff_wetlands\",\n",
        "    \"agriculture500\",\"airports500\", \"barren500\", \"industrial500\", \"industrial_transport500\", \"natural_green500\", \"ports500\", \"roads_rails500\", \"snow_ice500\",\n",
        "    \"transport500\", \"urban_fabric500\",\"urban_green500\", \"water500\", \"wetlands500\",\"diff_imd\",\"imd500\", \"diff_population\", \"population_500\",\"elevation\",\"Lat\",\"Lon\", \"area_grid\",\n",
        "    \"distance_border\", \"distance_mt\"]\n",
        "X = data.loc[: , covars]\n",
        "X = X.set_index(\"time\")"
      ],
      "metadata": {
        "id": "UGdd8jobeYOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-yPt5SYyzEn",
        "outputId": "df99cac1-931d-4627-e028-b06de05eb128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 102/102 [00:01<00:00, 54.96it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate train dataset and test dataset\n",
        "X_train = pd.DataFrame(np.zeros(X.shape[1])).T\n",
        "X_test = pd.DataFrame(np.zeros(X.shape[1])).T\n",
        "Y_train = pd.Series(0)\n",
        "Y_test = pd.Series(0)\n",
        "\n",
        "for station_id in tqdm(data.station_id.unique()):\n",
        "    # get station\n",
        "    X_station = X.loc[X.station_id == station_id, :]\n",
        "    Y_station = Y.loc[Y.station_id == station_id, :]\n",
        "    # train and test split (as in training data proportion)\n",
        "    split = 0.75\n",
        "    index_train = int(np.floor(len(X_station) * split))\n",
        "    Y_train_station = Y_station.iloc[:index_train,:]\n",
        "    Y_test_station = Y_station.iloc[index_train:, :]\n",
        "    X_train_station = X_station.iloc[:index_train,:]\n",
        "    X_test_station = X_station.iloc[index_train:,:]\n",
        "\n",
        "    X_train = pd.concat((X_train, X_train_station),axis = 0)\n",
        "    X_test = pd.concat((X_test, X_test_station),axis = 0)\n",
        "    Y_train = pd.concat ((Y_train, Y_train_station),axis = 0)\n",
        "    Y_test = pd.concat ((Y_test, Y_test_station),axis = 0)\n",
        "\n",
        "# remove first row/obs. of each df (fix here maybe)\n",
        "X_train = X_train.iloc[1:, 16:]\n",
        "X_train = X_train.fillna(0)\n",
        "X_test = X_test.iloc[1:, 16:]\n",
        "X_test = X_test.fillna(0)\n",
        "Y_train = Y_train.iloc[1:]\n",
        "Y_test = Y_test.iloc[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYY1N4mx6pCQ",
        "outputId": "3c15e553-cfa2-41cf-a63c-0e42601ed3ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mse ridge:  11.52213625435028\n"
          ]
        }
      ],
      "source": [
        "# global Ridge\n",
        "covars = [\"HOA_CAMX\", \"BBOA_CAMX\", \"OOAtot_CAMX\", \"year\", \"month\",\"day_week\",\n",
        "\"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\",\"diff_agriculture\", \"diff_airports\", \"diff_barren\", \"diff_industrial\", \"diff_industrial_transport\",\n",
        "    \"diff_natural_green\", \"diff_ports\", \"diff_roads_rails\", \"diff_snow_ice\", \"diff_transport\", \"diff_urban_fabric\", \"diff_urban_green\", \"diff_water\", \"diff_wetlands\",\n",
        "    \"agriculture500\",\"airports500\", \"barren500\", \"industrial500\", \"industrial_transport500\", \"natural_green500\", \"ports500\", \"roads_rails500\", \"snow_ice500\",\n",
        "    \"transport500\", \"urban_fabric500\",\"urban_green500\", \"water500\", \"wetlands500\",\"diff_imd\",\"imd500\", \"diff_population\", \"population_500\",\"elevation\",\"Lat\",\"Lon\", \"area_grid\",\n",
        "    \"distance_border\", \"distance_mt\"]\n",
        "X_fit_train = pd.concat(( X_train.loc[:, covars],  pd.get_dummies(X_train.station_id)), axis = 1)\n",
        "X_fit_test = pd.concat(( X_test.loc[:, covars],  pd.get_dummies(X_test.station_id)), axis = 1)\n",
        "ridge = RidgeCV()\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_fit_train)\n",
        "X_fit_train = pd.DataFrame(scaler.transform(X_fit_train))\n",
        "ridge.fit(X_fit_train, Y_train.OAtot_PMF)\n",
        "# predict\n",
        "y_rf = ridge.predict(pd.DataFrame(scaler.transform(X_fit_test)))\n",
        "# evaluate\n",
        "print(\"mse ridge: \", mse(Y_test.OAtot_PMF, y_rf))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unweighted\n",
        "full_ridge_glo_mse = {}\n",
        "full_ridge_glo_mape = {}\n",
        "for stat_id in data.station_id.unique():\n",
        "  x_test = X_fit_test.loc[X_test.station_id == stat_id,:]\n",
        "  x_test = pd.DataFrame(scaler.transform(x_test))\n",
        "  y_stat = Y_test.loc[X_test.station_id == stat_id,\"OAtot_PMF\"]\n",
        "  full_ridge_glo_mse[stat_id] = mse(y_stat, ridge.predict(x_test))\n",
        "  full_ridge_glo_mape[stat_id] = my_mape(y_stat, ridge.predict(x_test))"
      ],
      "metadata": {
        "id": "BCKrCy72jkXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"full ridge mse\", np.mean(list(full_ridge_glo_mse.values())), \"std.dev.: \", np.std(list(full_ridge_glo_mse.values())))\n",
        "print(\"full ridge mape\", np.mean(list(full_ridge_glo_mape.values())), \"std.dev.: \", np.std(list(full_ridge_glo_mape.values())))\n",
        "# save dict\n",
        "dictionaries = [full_ridge_glo_mse, full_ridge_glo_mape]\n",
        "names = [\"full_ridge_glo_mse\", \"full_ridge_glo_mape\"]\n",
        "for di, di_name in zip(dictionaries, names):\n",
        "  with open(di_name +\".json\", \"w\") as json_file:\n",
        "    json.dump(di, json_file)"
      ],
      "metadata": {
        "id": "3YKBBawPkdZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqZ0A8EX8EqU"
      },
      "outputs": [],
      "source": [
        "# global Ridge - NO CAMX\n",
        "covars = [ \"year\", \"month\",\"day_week\",\n",
        "\"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\",\"diff_agriculture\", \"diff_airports\", \"diff_barren\", \"diff_industrial\", \"diff_industrial_transport\",\n",
        "    \"diff_natural_green\", \"diff_ports\", \"diff_roads_rails\", \"diff_snow_ice\", \"diff_transport\", \"diff_urban_fabric\", \"diff_urban_green\", \"diff_water\", \"diff_wetlands\",\n",
        "    \"agriculture500\",\"airports500\", \"barren500\", \"industrial500\", \"industrial_transport500\", \"natural_green500\", \"ports500\", \"roads_rails500\", \"snow_ice500\",\n",
        "    \"transport500\", \"urban_fabric500\",\"urban_green500\", \"water500\", \"wetlands500\",\"diff_imd\",\"imd500\", \"diff_population\", \"population_500\",\"elevation\",\"Lat\",\"Lon\", \"area_grid\",\n",
        "    \"distance_border\", \"distance_mt\"]\n",
        "X_fit_train = pd.concat(( X_train.loc[:, covars],  pd.get_dummies(X_train.station_id)), axis = 1)\n",
        "X_fit_test = pd.concat(( X_test.loc[:, covars],  pd.get_dummies(X_test.station_id)), axis = 1)\n",
        "ridge = RidgeCV()\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_fit_train)\n",
        "X_fit_train = pd.DataFrame(scaler.transform(X_fit_train))\n",
        "ridge.fit(X_fit_train, Y_train.OAtot_PMF)\n",
        "# predict\n",
        "y_rf = ridge.predict(pd.DataFrame(scaler.transform(X_fit_test)))\n",
        "# evaluate\n",
        "print(\"mse ridge: \", mse(Y_test.OAtot_PMF, y_rf))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "part_ridge_glo_mse = {}\n",
        "part_ridge_glo_mape = {}\n",
        "for stat_id in data.station_id.unique():\n",
        "  x_test = X_fit_test.loc[X_test.station_id == stat_id,:]\n",
        "  x_test = pd.DataFrame(scaler.transform(x_test))\n",
        "  y_stat = Y_test.loc[X_test.station_id == stat_id, \"OAtot_PMF\"]\n",
        "  part_ridge_glo_mse[stat_id] = mse(y_stat, ridge.predict(x_test))\n",
        "  part_ridge_glo_mape[stat_id] = my_mape(y_stat, ridge.predict(x_test))"
      ],
      "metadata": {
        "id": "ym5xamnxks73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"part ridge mse\", np.mean(list(part_ridge_glo_mse.values())), \"std.dev.: \", np.std(list(part_ridge_glo_mse.values())))\n",
        "print(\"part ridge mape\", np.mean(list(part_ridge_glo_mape.values())), \"std.dev.: \", np.std(list(part_ridge_glo_mape.values())))\n",
        "# save dict\n",
        "dictionaries = [part_ridge_glo_mse, part_ridge_glo_mape]\n",
        "names = [\"part_ridge_glo_mse\", \"part_ridge_glo_mape\"]\n",
        "for di, di_name in zip(dictionaries, names):\n",
        "  with open(di_name +\".json\", \"w\") as json_file:\n",
        "    json.dump(di, json_file)\n"
      ],
      "metadata": {
        "id": "ArNVgsGHk2y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Itc86CgL38P"
      },
      "outputs": [],
      "source": [
        "# fit rf and boost with dummy\n",
        "covars = [ \"HOA_CAMX\", \"BBOA_CAMX\", \"OOAtot_CAMX\", \"year\", \"month\",\"day_week\",\n",
        "\"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\",\"diff_agriculture\", \"diff_airports\", \"diff_barren\", \"diff_industrial\", \"diff_industrial_transport\",\n",
        "    \"diff_natural_green\", \"diff_ports\", \"diff_roads_rails\", \"diff_snow_ice\", \"diff_transport\", \"diff_urban_fabric\", \"diff_urban_green\", \"diff_water\", \"diff_wetlands\",\n",
        "    \"agriculture500\",\"airports500\", \"barren500\", \"industrial500\", \"industrial_transport500\", \"natural_green500\", \"ports500\", \"roads_rails500\", \"snow_ice500\",\n",
        "    \"transport500\", \"urban_fabric500\",\"urban_green500\", \"water500\", \"wetlands500\",\"diff_imd\",\"imd500\", \"diff_population\", \"population_500\",\"elevation\",\"Lat\",\"Lon\", \"area_grid\",\n",
        "    \"distance_border\", \"distance_mt\"]\n",
        "X_fit_train = pd.concat(( X_train[covars],  pd.get_dummies(X_train.station_id)), axis = 1)\n",
        "X_fit_test = pd.concat(( X_test[covars],  pd.get_dummies(X_test.station_id)), axis = 1)\n",
        "rf  = RandomForestRegressor(random_state = 5, n_estimators = 500)\n",
        "boost = GradientBoostingRegressor(random_state = 5)\n",
        "# RF tunining\n",
        "param_rf = {\"max_features\":[\"sqrt\",\"log2\"]}\n",
        "clf_rf = RandomizedSearchCV(rf, param_rf)\n",
        "# Boosting tuning\n",
        "param_boost = {\"max_depth\":[3, 5, 7], \"learning_rate\":[0.1,0.01,0.001]}\n",
        "clf_boost = RandomizedSearchCV(boost, param_boost)\n",
        "# train\n",
        "clf_rf.fit(X_fit_train, Y_train.OAtot_PMF)\n",
        "clf_boost.fit(X_fit_train, Y_train.OAtot_PMF)\n",
        "# predict\n",
        "y_rf = clf_rf.predict(X_fit_test)\n",
        "y_boost = clf_boost.predict(X_fit_test)\n",
        "# evaluate\n",
        "print(\"mse of best individual model: \", 10.507)\n",
        "print(\"mse rf: \", mse(Y_test.OAtot_PMF, y_rf))\n",
        "print(\"mse boost: \", mse(Y_test.OAtot_PMF, y_boost))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unweighted results\n",
        "full_rf_glo_mse = {}\n",
        "full_boost_glo_mse = {}\n",
        "full_rf_glo_mape = {}\n",
        "full_boost_glo_mape = {}\n",
        "for stat_id in data.station_id.unique():\n",
        "  x_test = X_fit_test.loc[X_test.station_id == stat_id,:]\n",
        "  y_stat = Y_test.loc[X_test.station_id == stat_id, \"OAtot_PMF\"]\n",
        "  full_rf_glo_mse[stat_id] = mse(y_stat, clf_rf.predict(x_test))\n",
        "  full_boost_glo_mse[stat_id] = mse(y_stat, clf_boost.predict(x_test))\n",
        "  full_rf_glo_mape[stat_id] = my_mape(y_stat, clf_rf.predict(x_test))\n",
        "  full_boost_glo_mape[stat_id] = my_mape(y_stat, clf_boost.predict(x_test))\n",
        "## print results\n",
        "print(\"full rf mse:\", np.mean(list(full_rf_glo_mse.values())), \"std. dev: \", np.std(list(full_rf_glo_mse.values())))\n",
        "print(\"full boost mse:\", np.mean(list(full_boost_glo_mse.values())), \"std. dev: \", np.std(list(full_boost_glo_mse.values())))\n",
        "print(\"full rf mape:\", np.mean(list(full_rf_glo_mape.values())), \"std. dev: \", np.std(list(full_rf_glo_mape.values())))\n",
        "print(\"full boost mape:\", np.mean(list(full_boost_glo_mape.values())), \"std. dev: \", np.std(list(full_boost_glo_mape.values())))\n",
        "# save dict\n",
        "dictionaries = [full_rf_glo_mse, full_boost_glo_mse, full_rf_glo_mape, full_boost_glo_mape]\n",
        "names = [\"full_rf_glo_mse\", \"full_boost_glo_mse\", \"full_rf_glo_mape\", \"full_boost_glo_mape\"]\n",
        "for di, di_name in zip(dictionaries, names):\n",
        "  with open(di_name +\".json\", \"w\") as json_file:\n",
        "    json.dump(di, json_file)"
      ],
      "metadata": {
        "id": "ZtLcAT8qlZjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSg3dYaafq30"
      },
      "outputs": [],
      "source": [
        "# now without CAMx\n",
        "covars = [\"year\", \"month\",\"day_week\",\n",
        "\"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\",\"diff_agriculture\", \"diff_airports\", \"diff_barren\", \"diff_industrial\", \"diff_industrial_transport\",\n",
        "    \"diff_natural_green\", \"diff_ports\", \"diff_roads_rails\", \"diff_snow_ice\", \"diff_transport\", \"diff_urban_fabric\", \"diff_urban_green\", \"diff_water\", \"diff_wetlands\",\n",
        "    \"agriculture500\",\"airports500\", \"barren500\", \"industrial500\", \"industrial_transport500\", \"natural_green500\", \"ports500\", \"roads_rails500\", \"snow_ice500\",\n",
        "    \"transport500\", \"urban_fabric500\",\"urban_green500\", \"water500\", \"wetlands500\",\"diff_imd\",\"imd500\", \"diff_population\", \"population_500\",\"elevation\",\"Lat\",\"Lon\", \"area_grid\",\n",
        "    \"distance_border\", \"distance_mt\"]\n",
        "X_fit_train = pd.concat(( X_train.loc[:, covars],  pd.get_dummies(X_train.station_id)), axis = 1)\n",
        "X_fit_test = pd.concat(( X_test.loc[:, covars],  pd.get_dummies(X_test.station_id)), axis = 1)\n",
        "rf  = RandomForestRegressor(random_state = 5, n_estimators = 500)\n",
        "boost = GradientBoostingRegressor(random_state = 5)\n",
        "# RF tunining\n",
        "param_rf = {\"max_features\":[\"sqrt\",\"log2\"]}\n",
        "clf_rf = GridSearchCV(rf, param_rf)\n",
        "# Boosting tuning\n",
        "param_boost = {\"max_depth\":[3, 5, 7], \"learning_rate\":[0.1,0.01,0.001]}\n",
        "clf_boost = GridSearchCV(boost, param_boost)\n",
        "# train\n",
        "clf_rf.fit(X_fit_train, Y_train.OAtot_PMF)\n",
        "clf_boost.fit(X_fit_train, Y_train.OAtot_PMF)\n",
        "# predict\n",
        "y_rf = clf_rf.predict(X_fit_test)\n",
        "y_boost = clf_boost.predict(X_fit_test)\n",
        "# evaluate\n",
        "print(\"mse of best individual model: \", 10.507)\n",
        "print(\"mse rf: \", mse(Y_test.OAtot_PMF, y_rf))\n",
        "print(\"mse boost: \", mse(Y_test.OAtot_PMF, y_boost))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unweighted results\n",
        "part_rf_glo_mse = {}\n",
        "part_boost_glo_mse = {}\n",
        "part_rf_glo_mape = {}\n",
        "part_boost_glo_mape = {}\n",
        "for stat_id in data.station_id.unique():\n",
        "  x_test = X_fit_test.loc[X_test.station_id == stat_id,:]\n",
        "  y_stat = Y_test.loc[X_test.station_id == stat_id, \"OAtot_PMF\"]\n",
        "  part_rf_glo_mse[stat_id] = mse(y_stat, clf_rf.predict(x_test))\n",
        "  part_boost_glo_mse[stat_id] = mse(y_stat, clf_boost.predict(x_test))\n",
        "  part_rf_glo_mape[stat_id] = my_mape(y_stat, clf_rf.predict(x_test))\n",
        "  part_boost_glo_mape[stat_id] = my_mape(y_stat, clf_boost.predict(x_test))\n",
        "## print results\n",
        "print(\"part rf mse:\", np.mean(list(part_rf_glo_mse.values())), \"std. dev: \", np.std(list(part_rf_glo_mse.values())))\n",
        "print(\"part boost mse:\", np.mean(list(part_boost_glo_mse.values())), \"std. dev: \", np.std(list(part_boost_glo_mse.values())))\n",
        "print(\"part rf mape:\", np.mean(list(part_rf_glo_mape.values())), \"std. dev: \", np.std(list(part_rf_glo_mape.values())))\n",
        "print(\"part boost mape:\", np.mean(list(part_boost_glo_mape.values())), \"std. dev: \", np.std(list(part_boost_glo_mape.values())))\n",
        "# save dict\n",
        "dictionaries = [part_rf_glo_mse, part_boost_glo_mse, part_rf_glo_mape, part_boost_glo_mape]\n",
        "names = [\"part_rf_glo_mse\", \"part_boost_glo_mse\", \"part_rf_glo_mape\", \"part_boost_glo_mape\"]\n",
        "for di, di_name in zip(dictionaries, names):\n",
        "  with open(di_name +\".json\", \"w\") as json_file:\n",
        "    json.dump(di, json_file)\n"
      ],
      "metadata": {
        "id": "PMkGjlkJmY6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GP-BOOST"
      ],
      "metadata": {
        "id": "wFI-_Nxe6Nzk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpHE245kOVQP"
      },
      "outputs": [],
      "source": [
        "!pip install gpboost\n",
        "import gpboost as gpb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilaa2vdpL5sR"
      },
      "outputs": [],
      "source": [
        "#fit gp-boost with random effect per station\n",
        "# GP-BOOST\n",
        "# with station_id so to allow an interaction between random effect and fixed_effect predictors\n",
        "covars = [\"HOA_CAMX\", \"BBOA_CAMX\", \"OOAtot_CAMX\", \"year\", \"month\",\"day_week\",\n",
        "\"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\",\"diff_agriculture\", \"diff_airports\", \"diff_barren\", \"diff_industrial\", \"diff_industrial_transport\",\n",
        "    \"diff_natural_green\", \"diff_ports\", \"diff_roads_rails\", \"diff_snow_ice\", \"diff_transport\", \"diff_urban_fabric\", \"diff_urban_green\", \"diff_water\", \"diff_wetlands\",\n",
        "    \"agriculture500\",\"airports500\", \"barren500\", \"industrial500\", \"industrial_transport500\", \"natural_green500\", \"ports500\", \"roads_rails500\", \"snow_ice500\",\n",
        "    \"transport500\", \"urban_fabric500\",\"urban_green500\", \"water500\", \"wetlands500\",\"diff_imd\",\"imd500\", \"diff_population\", \"population_500\",\"elevation\",\"Lat\",\"Lon\", \"area_grid\",\n",
        "    \"distance_border\", \"distance_mt\"]\n",
        "data_train = gpb.Dataset(data=X_train.loc[:, covars], label=Y_train.OAtot_PMF)\n",
        "likelihood = \"gaussian\"\n",
        "groups = X_train.station_id\n",
        "gp_model = gpb.GPModel(group_data=X_train.loc[:, \"station_id\"], likelihood=likelihood)\n",
        "num_boost_round = 1000\n",
        "param_grid = {'learning_rate': [1,0.1,0.01, 0.001],\n",
        "                      'min_data_in_leaf': [10,100,1000],\n",
        "                      'max_depth': [1,2,3,5,10],\n",
        "                      'lambda_l2': [0,1,10]}\n",
        "other_params = {'num_leaves': 2**10, 'verbose': 0}\n",
        "opt_params = gpb.grid_search_tune_parameters(param_grid=param_grid, params=other_params,\n",
        "                                                    num_try_random=None, seed=1000, #n_folds = 4\n",
        "                                                    train_set=data_train, gp_model=gp_model, #, folds = folds, # folds = innner_kfold.split(X_train, Y_train, inner_groups), #stratified = True,\n",
        "                                                    use_gp_model_for_validation=True, verbose_eval=1,\n",
        "                                                    num_boost_round=num_boost_round, early_stopping_rounds=10, metric = \"mse\")\n",
        "# Train\n",
        "cvbst = gpb.cv(params=opt_params[\"best_params\"], train_set=data_train,\n",
        "               gp_model=gp_model, use_gp_model_for_validation=True, # folds = folds, # innner_kfold.split(X_train, Y_train, inner_groups),\n",
        "               num_boost_round=1000, early_stopping_rounds=50, #original 10\n",
        "               nfold=4, verbose_eval=True, show_stdv=False, seed=1)\n",
        "metric_name = list(cvbst.keys())[0]\n",
        "print(\"Best number of iterations: \" + str(np.argmin(cvbst[metric_name])))\n",
        "best_num_iter = np.argmin(cvbst[metric_name])\n",
        "print(best_num_iter)\n",
        "bst = gpb.train(params= opt_params['best_params'], train_set=data_train,  gp_model=gp_model,\n",
        "                    num_boost_round=best_num_iter)\n",
        "#gp_model.summary() # Estimated random effects model\n",
        "gp_pred = bst.predict(data=X_test.loc[:, covars], group_data_pred=X_test.station_id, predict_var=True, pred_latent=False)\n",
        "# print results\n",
        "print(\"mse gp-boost: \", mse(Y_test.OAtot_PMF, gp_pred[\"response_mean\"]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unweighted results\n",
        "full_gp_mse = {}\n",
        "full_gp_mape = {}\n",
        "\n",
        "for stat_id in data.station_id.unique():\n",
        "  x_test = X_test.loc[X_test.station_id == stat_id, covars]\n",
        "  y_stat = Y_test.loc[X_test.station_id == stat_id, \"OAtot_PMF\"]\n",
        "  group_data = X_test.loc[X_test.station_id == stat_id, \"station_id\"]\n",
        "  gp_pred = bst.predict(data=x_test, group_data_pred=group_data, predict_var=True, pred_latent=False)\n",
        "  full_gp_mse[stat_id] = mse(y_stat, gp_pred[\"response_mean\"])\n",
        "  full_gp_mape[stat_id] = my_mape(y_stat, gp_pred[\"response_mean\"])"
      ],
      "metadata": {
        "id": "edAVRta2lldG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print\n",
        "print(\"part gp mse:\", np.mean(list(full_gp_mse.values())), \"std. dev: \", np.std(list(full_gp_mse.values())))\n",
        "print(\"part gp mape:\", np.mean(list(full_gp_mape.values())), \"std. dev: \", np.std(list(full_gp_mape.values())))\n",
        "# save dict\n",
        "dictionaries = [full_gp_mse, full_gp_mape]\n",
        "names = [\"full_gp_mse\", \"full_gp_mape\"]\n",
        "for di, di_name in zip(dictionaries, names):\n",
        "  with open(di_name +\".json\", \"w\") as json_file:\n",
        "    json.dump(di, json_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UskJViS63QL",
        "outputId": "025b143e-6cd1-438c-bc7f-e83795d43fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part gp mse: 14.929502083458956 std. dev:  44.898420344350896\n",
            "part gp mape: 0.3807225745793061 std. dev:  0.2019996476458781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Nv6yT_malRZ"
      },
      "source": [
        "# PLOT RANDOM EFFECTS ON MAP OF EUROPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlqsWSkHakrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60418749-0030-497d-ce0e-6f00cdc838bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPSG:3035\n"
          ]
        }
      ],
      "source": [
        "# plot for Europe\n",
        "#load europe map\n",
        "path2 = \"/content/gdrive/MyDrive/Aurora_Thesis/NUTS_RG_20M_2021_3035.shp\"\n",
        "europe = gpd.read_file(path2)\n",
        "# Look at Coordinate Reference System (CRS)\n",
        "print(europe.crs)\n",
        "# Select Level Code\n",
        "europe = europe.loc[europe.LEVL_CODE == 1,:]\n",
        "# Remove remore French island\n",
        "europe = europe.loc[europe.NAME_LATN != \"RUP FR — Régions Ultrapériphériques Françaises\",:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5aGGSHnauso"
      },
      "outputs": [],
      "source": [
        "# make data.frame with stat_id, random effect, lat and lon\n",
        "# get variables ...\n",
        "# construct df\n",
        "gp_pred = bst.predict(data=X_test.loc[:, covars], group_data_pred=X_test.station_id, predict_var=True, pred_latent=True)\n",
        "res = pd.concat( (pd.DataFrame(gp_pred[\"random_effect_mean\"]),  X_test.Lat.reset_index(drop=True), X_test.Lon.reset_index(drop=True), Y_test.OAtot_PMF.reset_index(drop=True)),axis = 1)\n",
        "res = res.rename(columns={0:\"random_effect\"})\n",
        "res_gpd = gpd.GeoDataFrame(data = res, geometry= gpd.points_from_xy(x = res.Lon, y =  res.Lat), crs = 4326)\n",
        "res_gpd[\"abs_re\"] = np.abs(res_gpd.random_effect)\n",
        "res_gpd[\"fixed_effect\"] = gp_pred['fixed_effect']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ffkVcJ6auqh"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "ax = europe.plot(figsize=(16,9), rasterized = True)\n",
        "res_gpd.to_crs(\"epsg:3035\").plot(ax = ax,\n",
        "                                    column = res_gpd[\"random_effect\"],marker = \"o\",\n",
        "                                    cmap='plasma',legend=True,\n",
        "                                  rasterized = True, legend_kwds={\"label\": \"Random Effect\", \"orientation\": \"vertical\"}) #'shrink': 0.7\n",
        "xmin, xmax = 2*10**6 ,6.5*10**6\n",
        "ymin, ymax = 1*10**6, 6*10**6\n",
        "plt.xlim([xmin, xmax])\n",
        "plt.ylim([ymin, ymax])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHTKOTjpfzco"
      },
      "outputs": [],
      "source": [
        "# Without CAMx\n",
        "#fit gp-boost with random effect per station\n",
        "# with station_id so to allow an interaction between random effect and fixed_effect predictors\n",
        "covars = [\"year\", \"month\",\"day_week\",\n",
        "\"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\",\"diff_agriculture\", \"diff_airports\", \"diff_barren\", \"diff_industrial\", \"diff_industrial_transport\",\n",
        "    \"diff_natural_green\", \"diff_ports\", \"diff_roads_rails\", \"diff_snow_ice\", \"diff_transport\", \"diff_urban_fabric\", \"diff_urban_green\", \"diff_water\", \"diff_wetlands\",\n",
        "    \"agriculture500\",\"airports500\", \"barren500\", \"industrial500\", \"industrial_transport500\", \"natural_green500\", \"ports500\", \"roads_rails500\", \"snow_ice500\",\n",
        "    \"transport500\", \"urban_fabric500\",\"urban_green500\", \"water500\", \"wetlands500\",\"diff_imd\",\"imd500\", \"diff_population\", \"population_500\",\"elevation\",\"Lat\",\"Lon\", \"area_grid\",\n",
        "    \"distance_border\", \"distance_mt\"]\n",
        "data_train = gpb.Dataset(data=X_train.loc[:, covars], label=Y_train.OAtot_PMF)\n",
        "likelihood = \"gaussian\"\n",
        "groups = X_train.station_id\n",
        "gp_model = gpb.GPModel(group_data=groups, likelihood=likelihood)\n",
        "num_boost_round = 1000\n",
        "param_grid = {'learning_rate': [1,0.1,0.01, 0.001],\n",
        "                      'min_data_in_leaf': [10,100,1000],\n",
        "                      'max_depth': [1,2,3,5,10],\n",
        "                      'lambda_l2': [0,1,10]}\n",
        "other_params = {'num_leaves': 2**10, 'verbose': 0}\n",
        "opt_params = gpb.grid_search_tune_parameters(param_grid=param_grid, params=other_params,\n",
        "                                                    num_try_random=None, seed=1000, #n_folds = 4\n",
        "                                                    train_set=data_train, gp_model=gp_model, #, folds = folds, # folds = innner_kfold.split(X_train, Y_train, inner_groups), #stratified = True,\n",
        "                                                    use_gp_model_for_validation=True, verbose_eval=1,\n",
        "                                                    num_boost_round=num_boost_round, early_stopping_rounds=10, metric = \"mse\")\n",
        "# Train\n",
        "cvbst = gpb.cv(params=opt_params[\"best_params\"], train_set=data_train,\n",
        "               gp_model=gp_model, use_gp_model_for_validation=True, # folds = folds, # innner_kfold.split(X_train, Y_train, inner_groups),\n",
        "               num_boost_round=1000, early_stopping_rounds=50, #original 10\n",
        "               nfold=4, verbose_eval=True, show_stdv=False, seed=1)\n",
        "metric_name = list(cvbst.keys())[0]\n",
        "print(\"Best number of iterations: \" + str(np.argmin(cvbst[metric_name])))\n",
        "best_num_iter = np.argmin(cvbst[metric_name])\n",
        "print(best_num_iter)\n",
        "bst = gpb.train(params= opt_params['best_params'], train_set=data_train,  gp_model=gp_model,\n",
        "                    num_boost_round=best_num_iter)\n",
        "#gp_model.summary() # Estimated random effects model\n",
        "gp_pred = bst.predict(data=X_test.loc[:, covars], group_data_pred=X_test.station_id, predict_var=True, pred_latent=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unweighted results\n",
        "part_gp_mse = {}\n",
        "part_gp_mape = {}\n",
        "\n",
        "for stat_id in data.station_id.unique():\n",
        "  x_test = X_test.loc[X_test.station_id == stat_id, covars]\n",
        "  y_stat = Y_test.loc[X_test.station_id == stat_id, \"OAtot_PMF\"]\n",
        "  group_data = X_test.loc[X_test.station_id == stat_id, \"station_id\"]\n",
        "  gp_pred = bst.predict(data=x_test, group_data_pred=group_data, predict_var=True, pred_latent=False)\n",
        "  part_gp_mse[stat_id] = mse(y_stat, gp_pred[\"response_mean\"])\n",
        "  part_gp_mape[stat_id] = my_mape(y_stat, gp_pred[\"response_mean\"])"
      ],
      "metadata": {
        "id": "p-y4J2uHZsgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTQgB5tLf-6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e7bb4b-b054-41d2-f130-6a896d724d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part gp mse: 14.962123518215241 std. dev:  45.06108470770233\n",
            "part gp mape: 0.4018699344461716 std. dev:  0.21995060863960753\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "# print\n",
        "print(\"part gp mse:\", np.mean(list(part_gp_mse.values())), \"std. dev: \", np.std(list(part_gp_mse.values())))\n",
        "print(\"part gp mape:\", np.mean(list(part_gp_mape.values())), \"std. dev: \", np.std(list(part_gp_mape.values())))\n",
        "# save dict\n",
        "dictionaries = [part_gp_mse, part_gp_mape]\n",
        "names = [\"part_gp_mse\", \"part_gp_mape\"]\n",
        "for di, di_name in zip(dictionaries, names):\n",
        "  with open(di_name +\".json\", \"w\") as json_file:\n",
        "    json.dump(di, json_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "IML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}