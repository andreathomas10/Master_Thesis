{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error as mape, mean_squared_error as mse\n",
    "from pyarrow import feather as pq\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import Marker\n",
    "from shapely import geometry\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', None)\n",
    "from ipywidgets import interact\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "import mapie\n",
    "from mapie import regression\n",
    "from mapie.metrics import regression_coverage_score\n",
    "from mapie.regression import MapieRegressor\n",
    "from mapie.quantile_regression import MapieQuantileRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import shap\n",
    "# Feature Importance\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv(\"data_converted.csv\")\n",
    "data.time = pd.to_datetime(data.time)\n",
    "data = data.reset_index()\n",
    "# need to manually add 2 station Id\n",
    "data.loc[data.station== \"Bologna (BO)\", \"station_id\"] = \"ID1999\"\n",
    "data.loc[data.station== \"San Pietro Capofiume (SPC)\", \"station_id\"] = \"ID1998\"\n",
    "# switch London data\n",
    "data[\"OAtot_2\"] = data.HOA_PMF + data.BBOA_PMF + data.OOAtot_PMF\n",
    "data.loc[data.station == \"London\",\"OAtot_PMF\"] = data.loc[data.station == \"London\",\"OAtot_2\"]\n",
    "# Remove Zurich 2017\n",
    "data = data.loc[(data.station != \"Zurich\") | (data.year != 2017),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN DATA\n",
    "# remove OA with less than 0.1\n",
    "data= data.loc[data.OAtot_PMF >= 0.1, :]\n",
    "# and stations with less than 30 obs.\n",
    "select = (data.groupby(\"station_id\")[\"OAtot_PMF\"].size() > 30).reset_index()\n",
    "data = data.set_index(\"station_id\")\n",
    "data = data.join(select.set_index(\"station_id\"), rsuffix = \"keep\")\n",
    "data = data.loc[ data.OAtot_PMFkeep == True, :]\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add day of week\n",
    "data[\"day_week\"] = data.time.dt.day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "data[\"rc_1_1000-rc_1_100\"] = data[\"road_class_1_1000\"] - data[\"road_class_1_100\"]\n",
    "data[\"rc_2_1000-rc_2_100\"] = data[\"road_class_2_1000\"] - data[\"road_class_2_100\"]\n",
    "data[\"rc_3_1000-rc_3_100\"] = data[\"road_class_3_1000\"] - data[\"road_class_3_100\"]\n",
    "# CAMX proportions of components of OA\n",
    "data[\"p_HOA\"] = data[\"HOA_CAMX\"] / data[\"OAtot_CAMX\"]\n",
    "data[\"p_BBOA\"] = data[\"BBOA_CAMX\"] / data[\"OAtot_CAMX\"]\n",
    "data[\"p_OOAtot\"] = data[\"OOAtot_CAMX\"] / data[\"OAtot_CAMX\"]\n",
    "\n",
    "# need to decorralate some land-use variables\n",
    "data[\"diff_agriculture\"] = data[\"agriculture1000\"] - data[\"agriculture500\"]\n",
    "data[\"diff_airports\"] = data[\"airports1000\"] - data[\"airports500\"]\n",
    "data[\"diff_barren\"] = data[\"barren1000\"] - data[\"barren500\"]\n",
    "data[\"diff_industrial\"] = data[\"industrial1000\"] - data[\"industrial500\"]\n",
    "data[\"diff_industrial_transport\"]= data[\"industrial_transport1000\"] - data[\"industrial_transport500\"]\n",
    "data[\"diff_natural_green\"] =  data[\"natural_green1000\"] - data[\"natural_green500\"]\n",
    "data[\"diff_ports\"] = data[\"ports1000\"] - data[\"ports500\"]\n",
    "data[\"diff_roads_rails\"] = data[\"roads_rails1000\"] - data[\"roads_rails500\"]\n",
    "data[\"diff_snow_ice\"] = data[\"snow_ice1000\"] - data[\"snow_ice500\"]\n",
    "data[\"diff_transport\"] = data[\"transport1000\"] - data[\"transport500\"]\n",
    "data[\"diff_urban_fabric\"] = data[\"urban_fabric1000\"] - data[\"urban_fabric500\"]\n",
    "data[\"diff_urban_green\"] = data[\"urban_green1000\"] - data[\"urban_green500\"]\n",
    "data[\"diff_water\"] = data[\"water1000\"] - data[\"water500\"]\n",
    "data[\"diff_wetlands\"] = data[\"wetlands1000\"] - data[\"wetlands500\"]\n",
    "# also for Population and IMD\n",
    "data[\"diff_population\"] = data[\"population_1000\"] - data[\"population_500\"]\n",
    "data[\"diff_imd\"] = data[\"imd1000\"] - data[\"imd500\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOWN-SCALE AT UNSEEN LOCATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [2:46:26, 998.65s/it] \n"
     ]
    }
   ],
   "source": [
    "# Predict at unseen stations\n",
    "n_sp = 10\n",
    "cv = GroupKFold(n_splits = n_sp)\n",
    "res_rf = {}\n",
    "res_boost = {}\n",
    "covars = [\"HOA_CAMX\", \"BBOA_CAMX\", \"OOAtot_CAMX\", \"year\", \"month\",\"day_week\",\n",
    "\"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\",\"diff_agriculture\", \"diff_airports\", \"diff_barren\", \"diff_industrial\", \"diff_industrial_transport\",\n",
    "    \"diff_natural_green\", \"diff_ports\", \"diff_roads_rails\", \"diff_snow_ice\", \"diff_transport\", \"diff_urban_fabric\", \"diff_urban_green\", \"diff_water\", \"diff_wetlands\",\n",
    "    \"agriculture500\",\"airports500\", \"barren500\", \"industrial500\", \"industrial_transport500\", \"natural_green500\", \"ports500\", \"roads_rails500\", \"snow_ice500\",\n",
    "    \"transport500\", \"urban_fabric500\",\"urban_green500\", \"water500\", \"wetlands500\",\"diff_imd\",\"imd500\", \"diff_population\", \"population_500\",\"elevation\",\"Lat\",\"Lon\", \"area_grid\",\n",
    "    \"distance_border\", \"distance_mt\"]\n",
    "Y = data.loc[:, [\"time\",\"station\",\"OAtot_PMF\"]]\n",
    "Y = Y.set_index(\"time\")\n",
    "X = data.loc[:, covars]\n",
    "X = X.fillna(0)\n",
    "# Grouped Cross-Validation\n",
    "for idx, (train_idx, test_idx) in tqdm(enumerate(cv.split(X, Y, data.station_id))):\n",
    "    # get train ad test folds\n",
    "    X_train = X.iloc[train_idx,:]\n",
    "    X_train = X_train.fillna(0)\n",
    "    Y_train = Y.iloc[train_idx, :][\"OAtot_PMF\"]\n",
    "    X_test = X.iloc[test_idx, :]\n",
    "    X_test = X_test.fillna(0)\n",
    "    Y_test = Y.iloc[test_idx, :][\"OAtot_PMF\"]\n",
    "    # model\n",
    "    rf = RandomForestRegressor(random_state=10)\n",
    "    # Inner CV for parameter tuning\n",
    "    param_rf = {\"max_features\": [\"sqrt\",\"log2\"]}\n",
    "    inner_station_id = data.station_id.iloc[train_idx]\n",
    "    cv_inner = GroupKFold(n_splits = n_sp)\n",
    "    clf = GridSearchCV(rf, param_rf, cv =cv_inner.split(X_train, Y_train, inner_station_id ))\n",
    "    clf.fit(X_train, Y_train)\n",
    "    # boosting\n",
    "    boost = GradientBoostingRegressor()\n",
    "    param_boost = {\"learning_rate\": [0.1, 0.01, 0.05], \"max_depth\":[1,3,5]}\n",
    "    clf2 = GridSearchCV(boost, param_boost, cv =cv_inner.split(X_train, Y_train, inner_station_id ))\n",
    "    clf2.fit(X_train, Y_train)\n",
    "    # Predict at unseen station\n",
    "    test_stations = data.station_id.iloc[test_idx].unique()\n",
    "    for test_id in test_stations:\n",
    "        x_test = data.loc[data.station_id == test_id, covars]\n",
    "        x_test = x_test.fillna(0)\n",
    "        res_rf[test_id] = clf.predict(x_test)\n",
    "        res_boost[test_id] = clf2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_res(station_name):\n",
    "    id_station = data.loc[data.station == station_name, \"station_id\"].unique()\n",
    "    for id in id_station:\n",
    "        plt.figure(figsize=(16,9))\n",
    "        y_pred = res_rf[id]\n",
    "        Y_true = data.loc[data.station_id == id, \"OAtot_PMF\"]\n",
    "        Y_camx = data.loc[data.station_id == id, \"OAtot_CAMX\"]\n",
    "        plt.plot(Y_true.index, y_pred, label =\"Prediction\")\n",
    "        plt.plot(Y_true.index,Y_true, label =\"Observation\")\n",
    "        plt.plot(Y_true.index,Y_camx, label =\"CAMx\")\n",
    "        plt.title(station_name + \" \" + id)\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "                fancybox=True, shadow=True, ncol=5)\n",
    "        print(\"mse rf\", mse(Y_true, y_pred))\n",
    "        print(\"mse camx\", mse(Y_true, Y_camx))\n",
    "        print(\"mape rf\", mape(Y_true, y_pred))\n",
    "        print(\"mape camx\", mape(Y_true, Y_camx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_res, station_name = data.station.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mape(Y_true, Y_pred):\n",
    "    loss = (np.abs( (Y_true - Y_pred)/(Y_true + 1))).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_rf 30.279068471404102 std.dev:  115.32025850657475\n",
      "mse_boost 33.91150181876793 std.dev:  141.0740659634627\n",
      "mse_camx 41.368535130917905 std.dev:  150.1319050053784\n",
      "mape_rf 0.49977102754108427 std.dev:  0.30944158669665206\n",
      "mape_boost 0.46966484737643727 std.dev:  0.2831330396878055\n",
      "mape_camx 0.4489430055277247 std.dev:  0.16146792264629894\n"
     ]
    }
   ],
   "source": [
    "# get full results\n",
    "mse_rf = {}\n",
    "mse_boost = {}\n",
    "mse_camx = {}\n",
    "mape_rf = {}\n",
    "mape_boost = {}\n",
    "mape_camx = {}\n",
    "imp_rf_mse = 0\n",
    "imp_boost_mse = 0\n",
    "imp_rf_mape = 0\n",
    "imp_boost_mape =0\n",
    "\n",
    "for stat in data.station_id.unique():\n",
    "    y_pred_rf = res_rf[stat]\n",
    "    y_pred_boost = res_boost[stat]\n",
    "    Y_true = data.loc[data.station_id == stat, \"OAtot_PMF\"]\n",
    "    Y_camx = data.loc[data.station_id == stat, \"OAtot_CAMX\"]\n",
    "    \n",
    "    mse_rf[stat] = mse(Y_true, y_pred_rf)\n",
    "    mse_camx[stat] = mse(Y_true, Y_camx)\n",
    "    mse_boost[stat] =  mse(Y_true, y_pred_boost)\n",
    "    \n",
    "    mape_rf[stat]= my_mape(Y_true, y_pred_rf)\n",
    "    mape_boost[stat]= my_mape(Y_true, y_pred_boost)\n",
    "    mape_camx[stat] = my_mape(Y_true, np.array(Y_camx))\n",
    "\n",
    "print(\"mse_rf\", np.mean(list(mse_rf.values())), \"std.dev: \", np.std(list(mse_rf.values()))) \n",
    "print(\"mse_boost\", np.mean(list(mse_boost.values())), \"std.dev: \", np.std(list(mse_boost.values()))) \n",
    "print(\"mse_camx\", np.mean(list(mse_camx.values())) , \"std.dev: \", np.std(list(mse_camx.values())))\n",
    "print(\"mape_rf\",  np.mean(list(mape_rf.values())) , \"std.dev: \", np.std(list(mape_rf.values())))\n",
    "print(\"mape_boost\",  np.mean(list(mape_boost.values())) , \"std.dev: \", np.std(list(mape_boost.values())))\n",
    "print(\"mape_camx\",  np.mean(list(mape_camx.values())), \"std.dev: \", np.std(list(mape_camx.values())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE rf percentage of improved stations 0.8137254901960784\n",
      "MSE boost percentage of improved stations 0.8431372549019608\n",
      "MAPE rf percentage of improved stations 0.5294117647058824\n",
      "MAPE boost percentage of improved stations 0.6274509803921569\n"
     ]
    }
   ],
   "source": [
    "# percentage of improvements of RF wrt to CAMx\n",
    "imp_mse_rf = 0\n",
    "imp_mse_boost = 0\n",
    "imp_mape_rf = 0\n",
    "imp_mape_boost = 0\n",
    "n = len(list(mse_rf.values()))\n",
    "for i in range(n):\n",
    "    imp_mse_rf += (list(mse_rf.values())[i] < list(mse_camx.values())[i])*1\n",
    "    imp_mse_boost += (list(mse_boost.values())[i] < list(mse_camx.values())[i])*1\n",
    "    imp_mape_rf += (list(mape_rf.values())[i] < list(mape_camx.values())[i])*1\n",
    "    imp_mape_boost += (list(mape_boost.values())[i] < list(mape_camx.values())[i])*1\n",
    "print(\"MSE rf percentage of improved stations\", imp_mse_rf/n)\n",
    "print(\"MSE boost percentage of improved stations\", imp_mse_boost/n)\n",
    "print(\"MAPE rf percentage of improved stations\", imp_mape_rf/n)\n",
    "print(\"MAPE boost percentage of improved stations\", imp_mape_boost/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot\n",
    "sns.set_style(\"whitegrid\")\n",
    "labels = ['CAMx', 'Random Forest', 'Boosting']\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.boxplot([list(mse_camx.values()), list(mse_rf.values()), list(mse_boost.values()) ],labels = labels, patch_artist= \"blue\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"log(MSE)\", fontsize = 28)\n",
    "plt.tick_params(axis='x', labelsize=28) \n",
    "plt.tick_params(axis='y', labelsize=24)\n",
    "plt.title(\"MSE\", fontsize = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "labels = ['CAMx', 'Random Forest', 'Boosting']\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.boxplot([list(mape_camx.values()), list(mape_rf.values()), list(mape_boost.values()) ],labels = labels, patch_artist= \"blue\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"log(MAPE)\", fontsize = 28)\n",
    "plt.tick_params(axis='x', labelsize=28) \n",
    "plt.tick_params(axis='y', labelsize=24) \n",
    "plt.title(\"MAPE\", fontsize = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importances\n",
    "result = permutation_importance(clf, X, Y.OAtot_PMF, n_repeats=30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_sorted_idx = result.importances_mean.argsort()\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (16,9))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax1.boxplot(\n",
    "    result.importances[perm_sorted_idx][-10:].T,\n",
    "    vert=False,\n",
    "    labels=X.columns[perm_sorted_idx][-10:], patch_artist=True\n",
    ")\n",
    "plt.title(\"Permutation Feature Importance: Random Forest\", fontsize = 30)\n",
    "plt.xlabel(\"Average increase in loss\", fontsize = 28)\n",
    "plt.tick_params(axis='x', labelsize=24) \n",
    "plt.tick_params(axis='y', labelsize=24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
