{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Bias Analysis\n",
    "### Predicting absolute relative residuals at seen locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "!pip install shap\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error as mape, mean_squared_error as mse\n",
    "from pyarrow import feather as pq\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import Marker\n",
    "from shapely import geometry\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', None)\n",
    "from ipywidgets import interact\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import mapie\n",
    "from mapie import regression\n",
    "from mapie.metrics import regression_coverage_score\n",
    "from mapie.regression import MapieRegressor\n",
    "from mapie.quantile_regression import MapieQuantileRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import shap\n",
    "# Feature Importance\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv(\"data_converted.csv\")\n",
    "data.time = pd.to_datetime(data.time)\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN DATA\n",
    "# remove OA with less than 0.1\n",
    "data= data.loc[data.OAtot_PMF >= 0.1, :]\n",
    "# and stations with less than 30 obs.\n",
    "select = (data.groupby(\"station_id\")[\"OAtot_PMF\"].size() > 30).reset_index()\n",
    "data = data.set_index(\"station_id\")\n",
    "data = data.join(select.set_index(\"station_id\"), rsuffix = \"keep\")\n",
    "data = data.loc[ data.OAtot_PMFkeep == True, :]\n",
    "data = data.reset_index()\n",
    "# switch London data\n",
    "data[\"OAtot_2\"] = data.HOA_PMF + data.BBOA_PMF + data.OOAtot_PMF\n",
    "data.loc[data.station == \"London\",\"OAtot_PMF\"] = data.loc[data.station == \"London\",\"OAtot_2\"]\n",
    "# Remove Zurich 2017\n",
    "data = data.loc[(data.station != \"Zurich\") | (data.year != 2017),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OA\n",
    "data[\"day_of_week\"] = data.time.dt.day_of_week\n",
    "data = data.loc[data.OAtot_PMF.isnull()==False,:]\n",
    "data = data.sort_values(by=\"time\")\n",
    "# Get Y\n",
    "Y = data.loc[:, [\"time\",\"station\",\"OAtot_PMF\",\"OAtot_CAMX\"]]\n",
    "Y = Y.set_index(\"time\")\n",
    "# Get X design\n",
    "X = data.loc[: , [\"time\",\"station\", \"month\",\"week\",\"day_of_week\",\n",
    "\"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\"]]\n",
    "X = X.set_index(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_residuals(station_name, abs:bool, rel:bool):\n",
    "    \n",
    "    X_stat = X.loc[X.station == station_name,:]\n",
    "    Y_OA = Y.loc[Y.station == station_name , \"OAtot_PMF\"]\n",
    "    Y_CAMx = Y.loc[Y.station == station_name , \"OAtot_CAMX\"]\n",
    "    \n",
    "    # add delta of weather variables\n",
    "    X_stat[\"delta_rh\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_rh\"].iloc[1:] = np.array(X_stat[\"rh_CAMX\"].iloc[1:]) - np.array(X_stat[\"rh_CAMX\"].iloc[:-1])  \n",
    "    X_stat[\"delta_temp\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_temp\"].iloc[1:] = np.array(X_stat[\"temp_CAMX\"].iloc[1:]) - np.array(X_stat[\"temp_CAMX\"].iloc[:-1])  \n",
    "    X_stat[\"delta_press\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_press\"].iloc[1:] = np.array(X_stat[\"press_CAMX\"].iloc[1:]) - np.array(X_stat[\"press_CAMX\"].iloc[:-1])  \n",
    "    X_stat[\"delta_ws\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_ws\"].iloc[1:] = np.array(X_stat[\"ws_CAMX\"].iloc[1:]) - np.array(X_stat[\"ws_CAMX\"].iloc[:-1])  \n",
    "    X_stat[\"delta_wd\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_wd\"].iloc[1:] = np.array(X_stat[\"wd_CAMX\"].iloc[1:]) - np.array(X_stat[\"wd_CAMX\"].iloc[:-1])    \n",
    "    X_stat[\"delta_pblh\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_pblh\"].iloc[1:] = np.array(X_stat[\"pblh_CAMX\"].iloc[1:]) - np.array(X_stat[\"pblh_CAMX\"].iloc[:-1])    \n",
    "    X_stat[\"delta_wind_x\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_wind_x\"].iloc[1:] = np.array(X_stat[\"wind_x_CAMX\"].iloc[1:]) - np.array(X_stat[\"wind_x_CAMX\"].iloc[:-1])    \n",
    "    X_stat[\"delta_wind_y\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_wind_y\"].iloc[1:] = np.array(X_stat[\"wind_y_CAMX\"].iloc[1:]) - np.array(X_stat[\"wind_y_CAMX\"].iloc[:-1])    \n",
    "    X_stat = X_stat.fillna(0)\n",
    "    # if target is absolute residual\n",
    "    if abs:\n",
    "        Y_stat = np.abs(Y_OA - Y_CAMx)\n",
    "        if rel:\n",
    "            Y_stat = np.abs( (Y_OA - Y_CAMx)/(Y_OA + 1) )\n",
    "\n",
    "    else:\n",
    "        Y_stat = Y_OA - Y_CAMx\n",
    "        if rel:\n",
    "            Y_stat = (Y_OA - Y_CAMx) / (Y_OA + 1)\n",
    "        \n",
    "\n",
    "   \n",
    "\n",
    "    # Plot residual\n",
    "    fig, ax = plt.subplots(2, 1, figsize = (16,9))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    ax[0].plot(Y_stat, label = \"residual\")\n",
    "    ax[0].plot(Y_OA, label = \"OA\")\n",
    "    ax[0].plot(Y_CAMx, label = \"CAMx\")\n",
    "    ax[0].legend()\n",
    "    #ax[0].set_xticks(rotation = 45)\n",
    "    ax[0].set_title(station_name)\n",
    "    \n",
    "    # split in 2: train and test set\n",
    "    n = len(X_stat)\n",
    "    # indeces\n",
    "    end_train = np.floor(n*0.75).astype(int)\n",
    "    \n",
    "    # get data\n",
    "    X_train = X_stat.iloc[:end_train, :]\n",
    "    X_test = X_stat.iloc[end_train:, :]\n",
    "    Y_train = Y_stat.iloc[:end_train]\n",
    "    Y_test = Y_stat.iloc[end_train:]\n",
    "\n",
    "    # drop station from features\n",
    "    X_train = X_train.drop(\"station\",axis = 1)\n",
    "    X_test = X_test.drop(\"station\",axis = 1)\n",
    "    \n",
    "    # display plot\n",
    "    ax[1].plot(Y_train, label = \"train\")\n",
    "    ax[1].plot(Y_test, label = \"test\", color = \"pink\")\n",
    "    ax[1].set_title(station_name)\n",
    "    ax[1].set_xlabel(\"Time\")\n",
    "    ax[1].set_ylabel(\"OA\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    # RF\n",
    "    rf = RandomForestRegressor(n_estimators=500)\n",
    "    rf.fit(X_train.reset_index(drop=True), Y_train)\n",
    "    y_pred = rf.predict(X_test.reset_index(drop=True))\n",
    "    loss = mse(Y_test, y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (16,9))\n",
    "    ax[0].plot(Y_test, label = \"Observed residuals\", color = \"pink\")\n",
    "    ax[0].plot(Y_test.index, y_pred, label = \"Predicted residuals\", color = \"black\")\n",
    "    ax[0].set_title(str(station_name) + \" MSE: \" + str(loss))\n",
    "    ax[0].legend()\n",
    "\n",
    "    sns.regplot(x = Y_test, y = y_pred,ax = ax[1])\n",
    "    ax[1].axline(xy1 = (0,0), slope = 1,color = \"red\", label = \"identity\")\n",
    "    ax[1].set_xlabel(\"Y_test\")\n",
    "    ax[1].set_ylabel(\"Y_pred\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    result = permutation_importance(rf, X_test, Y_test, n_repeats=30, random_state=42)\n",
    "    perm_sorted_idx = result.importances_mean.argsort()\n",
    "    plt.figure(figsize = (20,9))\n",
    "    plt.boxplot(\n",
    "        result.importances[perm_sorted_idx].T,\n",
    "        vert=False,\n",
    "        labels=X_test.columns[perm_sorted_idx], patch_artist = True\n",
    "    )\n",
    "\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    \n",
    "\n",
    "\n",
    "    # select kind=\"individual\" to dispaly ICE plot\n",
    "    #plt.figure(figsize = (16,9))\n",
    "   # perm_sorted_idx = (-result.importances_mean).argsort()\n",
    "   # feature = X_test.columns[perm_sorted_idx][:3]\n",
    "    #PartialDependenceDisplay.from_estimator(rf, X_test, feature , kind =\"average\")\n",
    "    #ax.set_xticklabels(labels = ax.get_xticklabels(),fontsize = 50)\n",
    "    plt.figure(figsize = (16,9))\n",
    "    shap_values = shap.TreeExplainer(rf).shap_values(X_train.copy())\n",
    "    shap.summary_plot(shap_values, X_train.copy(), max_display=10) \n",
    "    #plt.figure(figsize=(16,9))\n",
    "    # Fits the explainer\n",
    "    # train or test data ?\n",
    "    #explainer = shap.Explainer(rf, X_test.reset_index(drop = True))\n",
    "    # Calculates the SHAP values - It takes some time\n",
    "    #shap_values = explainer(X_test.reset_index(drop = True), check_additivity=False)\n",
    "    #shap.plots.beeswarm(shap_values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47d5908164c45d2b93672e86bcceba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='station_name', options=('Virolahti II', 'Iskrba', 'Aspvreten', 'Isâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.shap_residuals(station_name, abs: bool, rel: bool)>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(shap_residuals, station_name = data.station.unique(), abs = [True, False], rel = [False, True])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute ranks and perform rank aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Y\n",
    "Y = data.loc[:, [\"time\",\"station_id\",\"OAtot_PMF\",\"OAtot_CAMX\"]]\n",
    "Y = Y.set_index(\"time\")\n",
    "# Get X design\n",
    "X = data.loc[: , [\"time\", \"station_id\", \"month\",\"week\",\"day_of_week\",\"temp_CAMX\", \"rh_CAMX\", \"press_CAMX\", \"ws_CAMX\", \"wd_CAMX\", \"pblh_CAMX\", \"wind_x_CAMX\", \"wind_y_CAMX\"]]\n",
    "X = X.set_index(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df to store results\n",
    "res = pd.DataFrame( np.zeros( (data.station_id.nunique() , len(X.columns) + 8))) \n",
    "res.columns = [*X.columns, \"delta_rh\", \"delta_temp\",\"delta_press\", \"delta_ws\",\n",
    "               \"delta_wd\", \"delta_pblh\", \"delta_wind_x\", \"delta_wind_y\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_residuals(station_id):\n",
    "    \n",
    "    X_stat = X.loc[X.station_id == station_id,:]\n",
    "    Y_OA = Y.loc[Y.station_id == station_id , \"OAtot_PMF\"]\n",
    "    Y_CAMx = Y.loc[Y.station_id == station_id , \"OAtot_CAMX\"]\n",
    "    \n",
    "    # add delta of weather variables\n",
    "    X_stat[\"delta_rh\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_rh\"].iloc[1:] = np.array(X_stat[\"rh_CAMX\"].iloc[1:]) - np.array(X_stat[\"rh_CAMX\"].iloc[:-1])  \n",
    "    X_stat[\"delta_temp\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_temp\"].iloc[1:] = np.array(X_stat[\"temp_CAMX\"].iloc[1:]) - np.array(X_stat[\"temp_CAMX\"].iloc[:-1])  \n",
    "    X_stat[\"delta_press\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_press\"].iloc[1:] = np.array(X_stat[\"press_CAMX\"].iloc[1:]) - np.array(X_stat[\"press_CAMX\"].iloc[:-1])  \n",
    "    X_stat[\"delta_ws\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_ws\"].iloc[1:] = np.array(X_stat[\"ws_CAMX\"].iloc[1:]) - np.array(X_stat[\"ws_CAMX\"].iloc[:-1])  \n",
    "    X_stat[\"delta_wd\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_wd\"].iloc[1:] = np.array(X_stat[\"wd_CAMX\"].iloc[1:]) - np.array(X_stat[\"wd_CAMX\"].iloc[:-1])    \n",
    "    X_stat[\"delta_pblh\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_pblh\"].iloc[1:] = np.array(X_stat[\"pblh_CAMX\"].iloc[1:]) - np.array(X_stat[\"pblh_CAMX\"].iloc[:-1])    \n",
    "    X_stat[\"delta_wind_x\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_wind_x\"].iloc[1:] = np.array(X_stat[\"wind_x_CAMX\"].iloc[1:]) - np.array(X_stat[\"wind_x_CAMX\"].iloc[:-1])    \n",
    "    X_stat[\"delta_wind_y\"] = np.zeros(len(X_stat))\n",
    "    X_stat[\"delta_wind_y\"].iloc[1:] = np.array(X_stat[\"wind_y_CAMX\"].iloc[1:]) - np.array(X_stat[\"wind_y_CAMX\"].iloc[:-1])    \n",
    "    \n",
    "    # target is residual\n",
    "    Y_stat = np.abs((Y_OA - Y_CAMx)/(Y_OA+1))\n",
    "    \n",
    "    # split in 2: train and test set\n",
    "    n = len(X_stat)\n",
    "    # indeces\n",
    "    end_train = np.floor(n*0.75).astype(int)\n",
    "    X_stat = X_stat.fillna(0)\n",
    "    # get data\n",
    "    X_train = X_stat.iloc[:end_train, :]\n",
    "    X_test = X_stat.iloc[end_train:, :]\n",
    "    Y_train = Y_stat.iloc[:end_train]\n",
    "    Y_test = Y_stat.iloc[end_train:]\n",
    "\n",
    "    # drop station from features\n",
    "    X_train = X_train.drop(\"station_id\",axis = 1)\n",
    "    X_test = X_test.drop(\"station_id\",axis = 1)\n",
    "\n",
    "    # RF\n",
    "    rf = RandomForestRegressor(n_estimators=500)\n",
    "    rf.fit(X_train.reset_index(drop=True), Y_train)\n",
    "    y_pred = rf.predict(X_test.reset_index(drop=True))\n",
    "    loss = mse(Y_test, y_pred)\n",
    "\n",
    "    # get permutation importance\n",
    "    result = permutation_importance(rf, X_test, Y_test, n_repeats=30, random_state=42)\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [24:47, 14.87s/it]\n"
     ]
    }
   ],
   "source": [
    "# iterate over station_id and store results\n",
    "for idx, stat in tqdm(enumerate(data.station_id.unique())):\n",
    "    result = importance_residuals(stat)\n",
    "    res.station_id.iloc[idx] = stat\n",
    "    res.loc[idx, res.columns[1:]] = result.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df for ranks for each station\n",
    "res_rank = res.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(res)):\n",
    "    res_rank.iloc[i,:].loc[(-res_rank.iloc[0]).sort_values().index] =((-res_rank.iloc[i]).sort_values().argsort()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate ranks in a robust way\n",
    "! pip install ranky\n",
    "import ranky as rk\n",
    "# average rank\n",
    "rk.show(np.sort(rk.borda(res.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "res_rank.T.mean(axis = 1).sort_values().plot(figsize = (16,9), kind = \"bar\")\n",
    "plt.ylabel(\"Avg. Rank\")\n",
    "plt.title(\"Rank aggregation of Permutation Feature Importance\", fontsize = 24)\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.ylabel(\"Average Rank\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other aggregation scheme: median rank\n",
    "plt.figure(figsize = (16,9))\n",
    "rk.show(rk.majority(res.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other aggregation scheme: kendal rank\n",
    "kendal_res = rk.center(res.T, method='kendalltau')\n",
    "kendal_res.plot(kind = \"bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
